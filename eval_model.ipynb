{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "import typing\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import OpenAIGPTLMHeadModel, OpenAIGPTConfig\n",
    "from muutils.logger import Logger, TimerContext\n",
    "from muutils.json_serialize import json_serialize, dataclass_serializer_factory\n",
    "from muutils.tensor_utils import ATensor\n",
    "from muutils.statcounter import StatCounter\n",
    "from muutils.misc import shorten_numerical_to_str\n",
    "\n",
    "from maze_transformer.generation.latticemaze import LatticeMaze\n",
    "from maze_transformer.generation.generators import LatticeMazeGenerators\n",
    "from maze_transformer.training.tokenizer import SolvedMaze, SPECIAL_TOKENS\n",
    "from maze_transformer.training.mazedataset import MazeDatasetConfig, MazeDataset\n",
    "from maze_transformer.evaluation.plot_maze import plot_multi_paths\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# bad hacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: load this from config\n",
    "\n",
    "_NODE_TOKEN_MAP_STR = {\n",
    "\t\"(0, 0)\": \"(0,0)\",\n",
    "\t\"(0, 1)\": \"(0,1)\",\n",
    "\t\"(0, 2)\": \"(0,2)\",\n",
    "\t\"(0, 3)\": \"(0,3)\",\n",
    "\t\"(1, 0)\": \"(1,0)\",\n",
    "\t\"(1, 1)\": \"(1,1)\",\n",
    "\t\"(1, 2)\": \"(1,2)\",\n",
    "\t\"(1, 3)\": \"(1,3)\",\n",
    "\t\"(2, 0)\": \"(2,0)\",\n",
    "\t\"(2, 1)\": \"(2,1)\",\n",
    "\t\"(2, 2)\": \"(2,2)\",\n",
    "\t\"(2, 3)\": \"(2,3)\",\n",
    "\t\"(3, 0)\": \"(3,0)\",\n",
    "\t\"(3, 1)\": \"(3,1)\",\n",
    "\t\"(3, 2)\": \"(3,2)\",\n",
    "\t\"(3, 3)\": \"(3,3)\"\n",
    "}\n",
    "\n",
    "NODE_TOKEN_MAP: dict[tuple[int,int], str] = {\n",
    "\teval(k): v for k, v in _NODE_TOKEN_MAP_STR.items()\n",
    "}\n",
    "\n",
    "TOKEN_ARR = [\n",
    "\t\"<ADJLIST_START>\",\n",
    "\t\"<ADJLIST_END>\",\n",
    "\t\"<TARGET_START>\",\n",
    "\t\"<TARGET_END>\",\n",
    "\t\"<START_PATH>\",\n",
    "\t\"<END_PATH>\",\n",
    "\t\"<-->\",\n",
    "\t\";\",\n",
    "\t\"<PADDING>\",\n",
    "\t\"(0,0)\",\n",
    "\t\"(0,1)\",\n",
    "\t\"(0,2)\",\n",
    "\t\"(0,3)\",\n",
    "\t\"(1,0)\",\n",
    "\t\"(1,1)\",\n",
    "\t\"(1,2)\",\n",
    "\t\"(1,3)\",\n",
    "\t\"(2,0)\",\n",
    "\t\"(2,1)\",\n",
    "\t\"(2,2)\",\n",
    "\t\"(2,3)\",\n",
    "\t\"(3,0)\",\n",
    "\t\"(3,1)\",\n",
    "\t\"(3,2)\",\n",
    "\t\"(3,3)\"\n",
    "]\n",
    "\n",
    "TOKENIZER_MAP = {\n",
    "\t\"<ADJLIST_START>\": 0,\n",
    "\t\"<ADJLIST_END>\": 1,\n",
    "\t\"<TARGET_START>\": 2,\n",
    "\t\"<TARGET_END>\": 3,\n",
    "\t\"<START_PATH>\": 4,\n",
    "\t\"<END_PATH>\": 5,\n",
    "\t\"<-->\": 6,\n",
    "\t\";\": 7,\n",
    "\t\"<PADDING>\": 8,\n",
    "\t\"(0,0)\": 9,\n",
    "\t\"(0,1)\": 10,\n",
    "\t\"(0,2)\": 11,\n",
    "\t\"(0,3)\": 12,\n",
    "\t\"(1,0)\": 13,\n",
    "\t\"(1,1)\": 14,\n",
    "\t\"(1,2)\": 15,\n",
    "\t\"(1,3)\": 16,\n",
    "\t\"(2,0)\": 17,\n",
    "\t\"(2,1)\": 18,\n",
    "\t\"(2,2)\": 19,\n",
    "\t\"(2,3)\": 20,\n",
    "\t\"(3,0)\": 21,\n",
    "\t\"(3,1)\": 22,\n",
    "\t\"(3,2)\": 23,\n",
    "\t\"(3,3)\": 24\n",
    "}\n",
    "\n",
    "model_cfg_inputs = {\"n_embed\": 32, \"n_layer\": 4, \"n_head\": 2, \"vocab_size\": 25, \"n_positions\": 90, \"pad_token_id\": 8, \"bos_token_id\": 8, \"eos_token_id\": 8}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# func defs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_model(model_path: str):\n",
    "\t\"\"\"\n",
    "\tLoad a model from a path.\n",
    "\t\"\"\"\n",
    "\tmodel = OpenAIGPTLMHeadModel(OpenAIGPTConfig(**model_cfg_inputs))\n",
    "\tstate_dict = torch.load(model_path)\n",
    "\tprint(state_dict.keys())\n",
    "\tmodel.load_state_dict(state_dict)\n",
    "\tmodel.eval()\n",
    "\tprint(f\"loaded model with {shorten_numerical_to_str(model.num_parameters())} parameters\")\n",
    "\treturn model\n",
    "\n",
    "\n",
    "def predict_tokens(model: OpenAIGPTLMHeadModel, inputs: ATensor, n_tokens: int = 32, **generate_kwargs):\n",
    "\t\"\"\"\n",
    "\tPredict the next token.\n",
    "\t\"\"\"\n",
    "\twith torch.no_grad():\n",
    "\t\tpredictions = model.generate(inputs, max_length=n_tokens, min_length=n_tokens, **generate_kwargs)\n",
    "\treturn predictions\n",
    "\n",
    "\n",
    "def plot_predicted_path(\n",
    "\t\tmodel_path: str,\n",
    "\t\tgrid_n: int = 4,\n",
    "\t):\n",
    "\n",
    "\t# TODO: load the config\n",
    "\n",
    "\t# generate a maze\n",
    "\tmaze: LatticeMaze = LatticeMazeGenerators.gen_dfs((grid_n, grid_n))\n",
    "\tc_start = (0, 0)\n",
    "\tc_end = (grid_n - 1, grid_n - 1)\n",
    "\n",
    "\t# solve the maze explicitly\n",
    "\tpath_true = np.array(maze.find_shortest_path(\n",
    "\t\tc_start = c_start,\n",
    "\t\tc_end = c_end,\n",
    "\t))\n",
    "\n",
    "\tsolved_maze: SolvedMaze = SolvedMaze(\n",
    "\t\tmaze=maze,\n",
    "\t\tsolution=np.array(maze.find_shortest_path(\n",
    "\t\t\tc_start=c_start,\n",
    "\t\t\tc_end=c_end,\n",
    "\t\t)),\n",
    "\t)\n",
    "\n",
    "\t# tokenize the maze\n",
    "\t# HACK: this is a hack to get the tokenizer to work\n",
    "\tmaze_only_tokens: list[str] = solved_maze.as_tokens(NODE_TOKEN_MAP, solution = False) + [ SPECIAL_TOKENS[\"start_path\"] ]\n",
    "\n",
    "\tprint(\"maze tokens:\", maze_only_tokens)\n",
    "\n",
    "\tarray_nopad = torch.tensor(\n",
    "\t\t[ TOKENIZER_MAP[t] for t in maze_only_tokens ], \n",
    "\t\tdtype=torch.int32,\n",
    "\t\tdevice=\"cpu\",\n",
    "\t)\n",
    "\n",
    "\tarray = torch.nn.functional.pad(\n",
    "\t\tarray_nopad, \n",
    "\t\t(90 - len(array_nopad), 0), \n",
    "\t\tvalue=8,\n",
    "\t)\n",
    "\n",
    "\t# have the model predict some tokens\n",
    "\tmodel = load_model(model_path)\n",
    "\tpredictions = predict_tokens(model, array.unsqueeze(0), 5)\n",
    "\n",
    "\tprint(predictions)\n",
    "\n",
    "\t\n",
    "\t# decode the tokens\n",
    "\tpredicted_tokens = [ TOKEN_ARR[t] for t in predictions[0] ]\n",
    "\t\n",
    "\tprint(predicted_tokens)\n",
    "\n",
    "\tpath_predicted: list[tuple[int,int]] = []\n",
    "\n",
    "\tfor token in predicted_tokens[len(maze_only_tokens):]:\n",
    "\t\tif token.startswith(\"(\"):\n",
    "\t\t\t# HACK (VERY BAD)\n",
    "\t\t\tcoord = eval(token)\n",
    "\t\t\tprint(coord)\n",
    "\t\t\tpath_predicted.append(coord)\n",
    "\n",
    "\t# plot the maze and both solutions\n",
    "\t# for label, fmt, color, path in paths\n",
    "\tplot_multi_paths(\n",
    "\t\tmaze = maze,\n",
    "\t\tpaths = [\n",
    "\t\t\t(path_true, \"true\", \"-\", \"red\"),\n",
    "\t\t\t(np.array(path_predicted), \"predicted\", \":\", \"blue\"),\n",
    "\t\t],\n",
    "\t)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maze tokens: ['<ADJLIST_START>', '(3,2)', '<-->', '(3,3)', ';', '(3,3)', '<-->', '(3,3)', ';', '(3,0)', '<-->', '(3,0)', ';', '(1,3)', '<-->', '(1,3)', ';', '(3,0)', '<-->', '(3,1)', ';', '(2,3)', '<-->', '(2,3)', ';', '(2,2)', '<-->', '(2,2)', ';', '(1,0)', '<-->', '(1,1)', ';', '(2,1)', '<-->', '(2,1)', ';', '(1,2)', '<-->', '(2,2)', ';', '(1,0)', '<-->', '(1,0)', ';', '(3,1)', '<-->', '(3,2)', ';', '(0,1)', '<-->', '(0,1)', ';', '(0,2)', '<-->', '(0,2)', ';', '(0,3)', '<-->', '(0,3)', ';', '(1,1)', '<-->', '(1,2)', ';', '<ADJLIST_END>', '<TARGET_START>', '(3,3)', '<TARGET_END>', '<START_PATH>']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Input length of input_ids is 90, but ``max_length`` is set to 5. This can lead to unexpected behavior. You should consider increasing ``config.max_length`` or ``max_length``.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odict_keys(['transformer.position_ids', 'transformer.tokens_embed.weight', 'transformer.positions_embed.weight', 'transformer.h.0.attn.bias', 'transformer.h.0.attn.c_attn.weight', 'transformer.h.0.attn.c_attn.bias', 'transformer.h.0.attn.c_proj.weight', 'transformer.h.0.attn.c_proj.bias', 'transformer.h.0.ln_1.weight', 'transformer.h.0.ln_1.bias', 'transformer.h.0.mlp.c_fc.weight', 'transformer.h.0.mlp.c_fc.bias', 'transformer.h.0.mlp.c_proj.weight', 'transformer.h.0.mlp.c_proj.bias', 'transformer.h.0.ln_2.weight', 'transformer.h.0.ln_2.bias', 'transformer.h.1.attn.bias', 'transformer.h.1.attn.c_attn.weight', 'transformer.h.1.attn.c_attn.bias', 'transformer.h.1.attn.c_proj.weight', 'transformer.h.1.attn.c_proj.bias', 'transformer.h.1.ln_1.weight', 'transformer.h.1.ln_1.bias', 'transformer.h.1.mlp.c_fc.weight', 'transformer.h.1.mlp.c_fc.bias', 'transformer.h.1.mlp.c_proj.weight', 'transformer.h.1.mlp.c_proj.bias', 'transformer.h.1.ln_2.weight', 'transformer.h.1.ln_2.bias', 'transformer.h.2.attn.bias', 'transformer.h.2.attn.c_attn.weight', 'transformer.h.2.attn.c_attn.bias', 'transformer.h.2.attn.c_proj.weight', 'transformer.h.2.attn.c_proj.bias', 'transformer.h.2.ln_1.weight', 'transformer.h.2.ln_1.bias', 'transformer.h.2.mlp.c_fc.weight', 'transformer.h.2.mlp.c_fc.bias', 'transformer.h.2.mlp.c_proj.weight', 'transformer.h.2.mlp.c_proj.bias', 'transformer.h.2.ln_2.weight', 'transformer.h.2.ln_2.bias', 'transformer.h.3.attn.bias', 'transformer.h.3.attn.c_attn.weight', 'transformer.h.3.attn.c_attn.bias', 'transformer.h.3.attn.c_proj.weight', 'transformer.h.3.attn.c_proj.bias', 'transformer.h.3.ln_1.weight', 'transformer.h.3.ln_1.bias', 'transformer.h.3.mlp.c_fc.weight', 'transformer.h.3.mlp.c_fc.bias', 'transformer.h.3.mlp.c_proj.weight', 'transformer.h.3.mlp.c_proj.bias', 'transformer.h.3.ln_2.weight', 'transformer.h.3.ln_2.bias', 'lm_head.weight'])\n",
      "loaded model with 28M parameters\n",
      "tensor([[ 8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,\n",
      "          8,  8,  0, 23,  6, 24,  7, 24,  6, 24,  7, 21,  6, 21,  7, 16,  6, 16,\n",
      "          7, 21,  6, 22,  7, 20,  6, 20,  7, 19,  6, 19,  7, 13,  6, 14,  7, 18,\n",
      "          6, 18,  7, 15,  6, 19,  7, 13,  6, 13,  7, 22,  6, 23,  7, 10,  6, 10,\n",
      "          7, 11,  6, 11,  7, 12,  6, 12,  7, 14,  6, 15,  7,  1,  2, 24,  3,  4,\n",
      "         10]])\n",
      "['<PADDING>', '<PADDING>', '<PADDING>', '<PADDING>', '<PADDING>', '<PADDING>', '<PADDING>', '<PADDING>', '<PADDING>', '<PADDING>', '<PADDING>', '<PADDING>', '<PADDING>', '<PADDING>', '<PADDING>', '<PADDING>', '<PADDING>', '<PADDING>', '<PADDING>', '<PADDING>', '<ADJLIST_START>', '(3,2)', '<-->', '(3,3)', ';', '(3,3)', '<-->', '(3,3)', ';', '(3,0)', '<-->', '(3,0)', ';', '(1,3)', '<-->', '(1,3)', ';', '(3,0)', '<-->', '(3,1)', ';', '(2,3)', '<-->', '(2,3)', ';', '(2,2)', '<-->', '(2,2)', ';', '(1,0)', '<-->', '(1,1)', ';', '(2,1)', '<-->', '(2,1)', ';', '(1,2)', '<-->', '(2,2)', ';', '(1,0)', '<-->', '(1,0)', ';', '(3,1)', '<-->', '(3,2)', ';', '(0,1)', '<-->', '(0,1)', ';', '(0,2)', '<-->', '(0,2)', ';', '(0,3)', '<-->', '(0,3)', ';', '(1,1)', '<-->', '(1,2)', ';', '<ADJLIST_END>', '<TARGET_START>', '(3,3)', '<TARGET_END>', '<START_PATH>', '(0,1)']\n",
      "(0, 1)\n",
      "(0, 2)\n",
      "(0, 2)\n",
      "(0, 3)\n",
      "(0, 3)\n",
      "(1, 1)\n",
      "(1, 2)\n",
      "(3, 3)\n",
      "(0, 1)\n",
      "(4, 4)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'path'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mf:\\conjecture\\maze-transformer\\eval_model.ipynb Cell 6'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/f%3A/conjecture/maze-transformer/eval_model.ipynb#ch0000005?line=0'>1</a>\u001b[0m plot_predicted_path(\u001b[39m\"\u001b[39;49m\u001b[39mdata/g4-n4K/g4-n4K_tiny-v1_2022-09-07-12-46-21/model_final.pt\u001b[39;49m\u001b[39m\"\u001b[39;49m, grid_n\u001b[39m=\u001b[39;49m\u001b[39m4\u001b[39;49m)\n",
      "\u001b[1;32mf:\\conjecture\\maze-transformer\\eval_model.ipynb Cell 5'\u001b[0m in \u001b[0;36mplot_predicted_path\u001b[1;34m(model_path, grid_n)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/conjecture/maze-transformer/eval_model.ipynb#ch0000004?line=85'>86</a>\u001b[0m \t\tpath_predicted\u001b[39m.\u001b[39mappend(coord)\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/conjecture/maze-transformer/eval_model.ipynb#ch0000004?line=87'>88</a>\u001b[0m \u001b[39m# plot the maze and both solutions\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/conjecture/maze-transformer/eval_model.ipynb#ch0000004?line=88'>89</a>\u001b[0m \u001b[39m# for label, fmt, color, path in paths\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/f%3A/conjecture/maze-transformer/eval_model.ipynb#ch0000004?line=89'>90</a>\u001b[0m plot_multi_paths(\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/conjecture/maze-transformer/eval_model.ipynb#ch0000004?line=90'>91</a>\u001b[0m \tmaze \u001b[39m=\u001b[39;49m maze,\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/conjecture/maze-transformer/eval_model.ipynb#ch0000004?line=91'>92</a>\u001b[0m \tpaths \u001b[39m=\u001b[39;49m [\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/conjecture/maze-transformer/eval_model.ipynb#ch0000004?line=92'>93</a>\u001b[0m \t\t(path_true, \u001b[39m\"\u001b[39;49m\u001b[39mtrue\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39m-\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mred\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/conjecture/maze-transformer/eval_model.ipynb#ch0000004?line=93'>94</a>\u001b[0m \t\t(np\u001b[39m.\u001b[39;49marray(path_predicted), \u001b[39m\"\u001b[39;49m\u001b[39mpredicted\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39m:\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mblue\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/conjecture/maze-transformer/eval_model.ipynb#ch0000004?line=94'>95</a>\u001b[0m \t],\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/conjecture/maze-transformer/eval_model.ipynb#ch0000004?line=95'>96</a>\u001b[0m )\n",
      "File \u001b[1;32mf:\\conjecture\\maze-transformer\\maze_transformer\\evaluation\\plot_maze.py:49\u001b[0m, in \u001b[0;36mplot_multi_paths\u001b[1;34m(maze, paths, show)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[39m# plot paths\u001b[39;00m\n\u001b[0;32m     48\u001b[0m \u001b[39mfor\u001b[39;00m pf \u001b[39min\u001b[39;00m paths:\n\u001b[1;32m---> 49\u001b[0m \tp_transformed: NDArray \u001b[39m=\u001b[39m maze\u001b[39m.\u001b[39mpoints_transform_to_img(pf\u001b[39m.\u001b[39;49mpath)\n\u001b[0;32m     51\u001b[0m \tplt\u001b[39m.\u001b[39mplot(\u001b[39m*\u001b[39m\u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mp_transformed), pf\u001b[39m.\u001b[39mfmt, color\u001b[39m=\u001b[39mpf\u001b[39m.\u001b[39mcolor, label\u001b[39m=\u001b[39mpf\u001b[39m.\u001b[39mlabel)\n\u001b[0;32m     52\u001b[0m \t\u001b[39m# mark endpoints\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'path'"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_predicted_path(\"data/g4-n4K/g4-n4K_tiny-v1_2022-09-07-12-46-21/model_final.pt\", grid_n=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "826cdf1d6a1d995932fcc4b02bd7049699ce423053098b308e34496c9b855014"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
