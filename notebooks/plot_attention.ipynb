{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "import typing\n",
    "import html\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import OpenAIGPTLMHeadModel, OpenAIGPTConfig\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from muutils.logger import Logger, TimerContext\n",
    "from muutils.json_serialize import json_serialize, dataclass_serializer_factory\n",
    "from muutils.tensor_utils import ATensor, NDArray\n",
    "from muutils.statcounter import StatCounter\n",
    "from muutils.misc import shorten_numerical_to_str\n",
    "\n",
    "import IPython\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "\n",
    "from maze_transformer.generation.latticemaze import LatticeMaze\n",
    "from maze_transformer.generation.generators import LatticeMazeGenerators\n",
    "from maze_transformer.training.tokenizer import MazeTokenizer, SPECIAL_TOKENS\n",
    "from maze_transformer.training.mazedataset import MazeDatasetConfig, MazeDataset\n",
    "from maze_transformer.evaluation.plot_maze import plot_multi_paths, PathFormat\n",
    "from maze_transformer.training.dataset import GPTDatasetConfig\n",
    "from maze_transformer.training.config import TrainConfig\n",
    "from maze_transformer.training.training import TRAIN_SAVE_FILES\n",
    "from maze_transformer.evaluation.eval_model import generate_plot_predicted_path, MazePath, load_model_with_configs, LoadedModelConfigs, predict_maze_path\n",
    "from maze_transformer.evaluation.pathdist import MazeEvalFunction, ArrMazeEvalFunction, MazeEvalFuncs, ArrMazeEvalFuncs\n",
    "from maze_transformer.evaluation.eval_model import decode_maze_tokens_to_coords, predict_tokens, pad_sequence\n",
    "from maze_transformer.evaluation.plot_attention import colorize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'search_env' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n search_env ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# load model and configs\n",
    "model_path: str = \"data/g4-n4K/g4-n4K_tiny-v1_2022-10-05-02-03-44/model.final.pt\"\n",
    "loaded_model_and_configs: LoadedModelConfigs = load_model_with_configs(model_path, MazeDatasetConfig)\n",
    "data_cfg: MazeDatasetConfig; train_cfg: TrainConfig\n",
    "model_cfg: OpenAIGPTConfig; model: OpenAIGPTLMHeadModel\n",
    "data_cfg, train_cfg, model_cfg, model = loaded_model_and_configs\n",
    "\n",
    "model.config.max_length = model_cfg.n_positions + 1\n",
    "model.config.output_attentions = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'search_env' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n search_env ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "\n",
    "# generate a maze\n",
    "\n",
    "grid_n: int = data_cfg.grid_n\n",
    "maze: LatticeMaze = LatticeMazeGenerators.gen_dfs((grid_n, grid_n))\n",
    "c_start = (0, 0)\n",
    "c_end = (grid_n - 1, grid_n - 1)\n",
    "\n",
    "# solve the maze explicitly\n",
    "path_true = np.array(maze.find_shortest_path(\n",
    "\tc_start = c_start,\n",
    "\tc_end = c_end,\n",
    "))\n",
    "\n",
    "solved_maze: MazeTokenizer = MazeTokenizer(\n",
    "\tmaze=maze,\n",
    "\tsolution=np.array(maze.find_shortest_path(\n",
    "\t\tc_start=c_start,\n",
    "\t\tc_end=c_end,\n",
    "\t)),\n",
    ")\n",
    "\n",
    "# tokenize the maze\n",
    "maze_only_tokens: list[str] = solved_maze.as_tokens(data_cfg.node_token_map , solution = False) + [ SPECIAL_TOKENS[\"start_path\"] ]\n",
    "\n",
    "print(\"maze tokens:\", maze_only_tokens)\n",
    "\n",
    "array_nopad = torch.tensor(\n",
    "\t[ data_cfg.tokenizer_map[t] for t in maze_only_tokens ], \n",
    "\tdtype=torch.int32,\n",
    "\tdevice=\"cpu\",\n",
    ")\n",
    "\n",
    "array: ATensor = pad_sequence(array_nopad, model_cfg)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'search_env' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n search_env ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# have the model predict some tokens\n",
    "\n",
    "n_positions: int = model_cfg.n_positions\n",
    "\n",
    "context_str: list[str] = maze_only_tokens[-model.config.n_positions:]\n",
    "# left pad with <NULL>\n",
    "context_str = [\n",
    "\tSPECIAL_TOKENS[\"padding\"] \n",
    "\tfor _ in range(\n",
    "\t\tn_positions - len(context_str)\n",
    "\t)\n",
    "] + context_str\n",
    "# escape for html\n",
    "context_str = [ html.escape(t) for t in context_str ]\n",
    "context_tokenized: list[int] = array[-model.config.n_positions:]\n",
    "\n",
    "with torch.no_grad():\n",
    "\toutput = model(array[-model.config.n_positions:])\n",
    "\n",
    "print(f\"{output.logits.shape = }\\n{len(output.attentions) = }\\n{[x.shape for x in output.attentions] = }\")\n",
    "\n",
    "# `output.attentions` is a tuple of tensors, where each element of the tuple corresponds to a layer. The tensor has dimensions (1, n_heads, n_positions, n_positions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'search_env' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n search_env ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "n_layers: int = len(output.attentions)\n",
    "n_heads: int = output.attentions[0].shape[1]\n",
    "fig, axs = plt.subplots(n_layers, n_heads, figsize=(10 * n_heads, 10 * n_layers))\n",
    "\n",
    "for layer_idx, layer in enumerate(output.attentions):\n",
    "\tfor head_idx, head in enumerate(layer[0]):\n",
    "\t\thead_np = head.cpu().numpy()\n",
    "\t\t# make the values more visible by taking the nth root\n",
    "\t\thead_np = np.power(head_np, 1/4)\n",
    "\n",
    "\t\taxs[layer_idx, head_idx].imshow(head_np, cmap=\"gray\")\n",
    "\t\taxs[layer_idx, head_idx].set_title(f\"layer {layer_idx}, head {head_idx}\")\n",
    "\n",
    "\t\t\n",
    "\n",
    "\t\t# set x and y axes to words from context_str\n",
    "\t\t# axs[layer_idx, head_idx].set_xticks(range(n_positions), context_str)\n",
    "\t\t# axs[layer_idx, head_idx].set_yticks(range(n_positions), context_str)\n",
    "\n",
    "\t\t# # rotate x axis labels\n",
    "\t\t# plt.setp(axs[layer_idx, head_idx].get_xticklabels(), rotation=45, ha=\"right\", rotation_mode=\"anchor\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'search_env' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n search_env ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# for layer_idx, layer in enumerate(output.attentions):\n",
    "layer = output.attentions[-1]\n",
    "head_cmaps: list[str] = [ \"Blues\", \"Reds\" ]\n",
    "for head_idx, head in enumerate(layer[0]):\n",
    "\thead_np = head.cpu().numpy()\n",
    "\tfinal_attn = np.power(head_np[-1], 1/4)\n",
    "\twords_colored = colorize(context_str, final_attn, cmap = head_cmaps[head_idx])\n",
    "\tIPython.display.display(IPython.display.HTML(words_colored))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'search_env' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n search_env ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "print(predictions)\n",
    "\n",
    "# decode the tokens\n",
    "predicted_tokens = [ data_cfg.token_arr[t] for t in predictions[0] ]\n",
    "\n",
    "print(predicted_tokens)\n",
    "\n",
    "path_predicted: list[tuple[int,int]] = decode_maze_tokens_to_coords(\n",
    "\tpredicted_tokens[len(maze_only_tokens):],\n",
    "\tmazedata_cfg = data_cfg, \n",
    "\twhen_noncoord = \"skip\",\n",
    ")\n",
    "\n",
    "# plot the maze and both solutions\n",
    "# for label, fmt, color, path in paths\n",
    "plot_multi_paths(\n",
    "\tmaze = maze,\n",
    "\tpaths = [\n",
    "\t\tPathFormat(path_true, \"true\", \"-\", \"red\", {'width': 0.015}),\n",
    "\t\tPathFormat(np.array(path_predicted), \"predicted\", \":\", \"blue\", {}),\n",
    "\t],\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "search_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "62905ad46d100ac3585b269e697bed797f99f9269c8442add34dc9bf06a84d9c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
