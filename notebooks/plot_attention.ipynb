{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Generic\n",
    "import html\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Transformers\n",
    "from circuitsvis.attention import attention_heads\n",
    "from circuitsvis.tokens import colored_tokens_multi\n",
    "\n",
    "# Numerical Computing\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# Our Code\n",
    "from maze_transformer.utils.notebook_utils import configure_notebook\n",
    "from maze_transformer.generation.latticemaze import LatticeMaze\n",
    "from maze_transformer.generation.generators import LatticeMazeGenerators\n",
    "from maze_transformer.training.tokenizer import MazeTokenizer, SPECIAL_TOKENS, HuggingMazeTokenizer\n",
    "from maze_transformer.evaluation.plot_maze import plot_multi_paths, PathFormat\n",
    "from maze_transformer.evaluation.eval_model import decode_maze_tokens_to_coords, load_model_with_configs"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Setup\n",
    "device = configure_notebook(seed=42, dark_mode=True)\n",
    "# We won't be training any models\n",
    "torch.set_grad_enabled(False)\n",
    "\n",
    "\n",
    "# Get latest model\n",
    "# this should point towards a directory containing a run. If you don't have any runs, you can use `poetry run python scripts/create_dataset.py create ./data/maze 10 --grid_n=4`\n",
    "run_path = Path(\"../data/maze/g4-n10\")\n",
    "assert run_path.exists(), f\"Run path {run_path.as_posix()} does not exist\"\n",
    "model_path = list(sorted(run_path.glob(\"**/model.final.pt\"), key=os.path.getmtime))[\n",
    "\t-1\n",
    "].resolve()\n",
    "model, cfg = load_model_with_configs(model_path)\n",
    "maze_path = run_path / \"maze_tokens.jsonl\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# generate a maze\n",
    "grid_n: int = cfg.dataset_cfg.grid_n\n",
    "maze: LatticeMaze = LatticeMazeGenerators.gen_dfs((grid_n, grid_n))\n",
    "c_start = (0, 0)\n",
    "c_end = (grid_n - 1, grid_n - 1)\n",
    "\n",
    "# solve the maze explicitly\n",
    "path_true = np.array(maze.find_shortest_path(\n",
    "\tc_start = c_start,\n",
    "\tc_end = c_end,\n",
    "))\n",
    "\n",
    "solved_maze: MazeTokenizer = MazeTokenizer(\n",
    "\tmaze=maze,\n",
    "\tsolution=path_true,\n",
    ")\n",
    "\n",
    "# tokenize the maze\n",
    "maze_only_tokens: list[str] = solved_maze.as_tokens(cfg.dataset_cfg.node_token_map , solution = False) + [ SPECIAL_TOKENS[\"path_start\"] ]\n",
    "\n",
    "print(\"maze tokens:\", maze_only_tokens)\n",
    "\n",
    "array = model.to_tokens(\" \".join(maze_only_tokens), prepend_bos=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits.shape = torch.Size([1, 38, 18])\n",
      "len(attentions) = 4\n",
      "[x.shape for x in attentions] = [torch.Size([1, 2, 38, 38]), torch.Size([1, 2, 38, 38]), torch.Size([1, 2, 38, 38]), torch.Size([1, 2, 38, 38])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2401784/1285469696.py:7: UserWarning:\n",
      "\n",
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "\n"
     ]
    }
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# have the model predict some tokens\n",
    "context_str: list[str] = maze_only_tokens\n",
    "\n",
    "# escape for html\n",
    "context_str = [ html.escape(t) for t in context_str ]\n",
    "\n",
    "array_tensor = torch.tensor(array).long().to(device)\n",
    "with torch.no_grad():\n",
    "\tlogits, cache = model.run_with_cache(array_tensor)\n",
    "\n",
    "attentions = [w for k, w in cache.items() if 'hook_pattern' in k]\n",
    "print(f\"{logits.shape = }\\n{len(attentions) = }\\n{[x.shape for x in attentions] = }\")\n",
    "\n",
    "# `output.attentions` is a tuple of tensors, where each element of the tuple corresponds to a layer. \n",
    "#  The tensor has dimensions (1, n_heads, n_positions, n_positions)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "n_layers: int = len(attentions)\n",
    "n_heads: int = attentions[0].shape[1]\n",
    "n_tokens: int = attentions[0].shape[2]\n",
    "attention_to_plot = torch.concatenate(attentions, dim=0).reshape(-1, n_tokens, n_tokens)\n",
    "attention_head_names = [f\"Layer {i} Head {j}\" for i in range(n_layers) for j in range(n_heads)]\n",
    "attention_heads(attention_to_plot,maze_only_tokens, attention_head_names)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#! ALEX note - there used to be a np.power(head_np, 1/4) here, not sure what that's about?\n",
    "FROM_TOKEN = -1 # Look at attention from this token position to the rest of the sequence\n",
    "attentions_from_token = torch.concatenate([w[0, :, FROM_TOKEN, :] for w in attentions], dim=0)\n",
    "colored_tokens_multi(context_str, attentions_from_token.T, labels=attention_head_names)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def prediction_contained_a_coordinate_token(tokens: list[str], tokenizer: HuggingMazeTokenizer) -> bool:\n",
    "\t\"\"\"Check if the prediction contains a coordinate token\"\"\"\n",
    "\tfor t in tokens:\n",
    "\t\tif t not in list(tokenizer.special_tokens_map.values()) + tokenizer.additional_special_tokens:\n",
    "\t\t\treturn True\n",
    "\tprint(\"FAIL: Sampled a path - No coordinate token found before EOS\")\n",
    "\treturn False\n",
    "\n",
    "predicted_tokens = []\n",
    "while not prediction_contained_a_coordinate_token(predicted_tokens, model.tokenizer):\n",
    "\tpredictions = model.generate(array_tensor, max_new_tokens=50, stop_at_eos=True, verbose=False)\n",
    "\tpredicted_tokens = model.to_str_tokens(predictions)[len(maze_only_tokens):]\n",
    "print(\"SUCCESS: Model predicted the path:\")\n",
    "print(predicted_tokens)\n",
    "\n",
    "path_predicted: list[tuple[int,int]] = decode_maze_tokens_to_coords(\n",
    "\tpredicted_tokens,\n",
    "\tmazedata_cfg = cfg.dataset_cfg, \n",
    "\twhen_noncoord = \"skip\",\n",
    ")\n",
    "\n",
    "# plot the maze and both solutions\n",
    "# for label, fmt, color, path in paths\n",
    "plot_multi_paths(\n",
    "\tmaze = maze,\n",
    "\tpaths = [\n",
    "\t\tPathFormat(path_true, \"true\", \"-\", \"red\", {'width': 0.015}),\n",
    "\t\tPathFormat(np.array(path_predicted), \"predicted\", \":\", \"blue\", {}),\n",
    "\t],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mml_cw_new",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "170637793197da0d440deb6cb249c898d613b24c548839ecbbac11596710dfc2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}