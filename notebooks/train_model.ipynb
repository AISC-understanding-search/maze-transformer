{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generic\n",
    "import typing\n",
    "import os\n",
    "from pathlib import Path\n",
    "import typing\n",
    "import json\n",
    "\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Numerical Computing\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# muutils\n",
    "from muutils.zanj.zanj import ZANJ, ZANJ_GLOBAL_DEFAULTS\n",
    "\n",
    "# Our Code\n",
    "from maze_transformer.utils.notebook_utils import configure_notebook\n",
    "from maze_transformer.training.config import ConfigHolder, ZanjHookedTransformer, BaseGPTConfig, TrainConfig\n",
    "from maze_transformer.dataset.maze_dataset import MazeDataset, MazeDatasetConfig\n",
    "from maze_transformer.dataset.maze_dataset_configs import MAZE_DATASET_CONFIGS\n",
    "from maze_transformer.generation.generators import LatticeMazeGenerators\n",
    "from maze_transformer.training.train_model import TrainingResult, train_model\n",
    "from maze_transformer.training.wandb_logger import WandbProject\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEVICE = device(type='cpu')\n"
     ]
    }
   ],
   "source": [
    "# set global defaults for ZANJ\n",
    "ZANJ_GLOBAL_DEFAULTS.external_array_threshold = 1024\n",
    "ZANJ_GLOBAL_DEFAULTS.external_list_threshold = 1024\n",
    "\n",
    "# paths\n",
    "PATH_EXAMPLES: Path = Path(\"../examples/\")\n",
    "PATH_DATA: Path = Path(\"../data/\")\n",
    "\n",
    "# reproducibility and device\n",
    "DEVICE = configure_notebook(seed=42, dark_mode=True)\n",
    "print(f\"{DEVICE = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list(MAZE_DATASET_CONFIGS.keys()) = ['test-g3-n5-a_dfs-h82387', 'demo_small-g3-n100-a_dfs-h69818', 'demo-g6-n10K-a_dfs-h92077']\n"
     ]
    }
   ],
   "source": [
    "print(f\"{list(MAZE_DATASET_CONFIGS.keys()) = }\")\n",
    "\n",
    "# if you want to specify a custom config, you can do so here\n",
    "CFG_CUSTOM: ConfigHolder = ConfigHolder(\n",
    "    name = \"custom\",\n",
    "    dataset_cfg = MazeDatasetConfig(\n",
    "\t\tname=\"custom-dataset\",\n",
    "\t\tgrid_n=6,\n",
    "\t\tn_mazes=10000,\n",
    "\t\tmaze_ctor=LatticeMazeGenerators.gen_dfs,\n",
    "\t),\n",
    "    model_cfg = BaseGPTConfig(\n",
    "        name=\"custom-model\",\n",
    "        act_fn=\"gelu\",\n",
    "        d_model=8,\n",
    "        d_head=4,\n",
    "        n_layers=2,\n",
    "    ),\n",
    "    train_cfg = TrainConfig(\n",
    "        name=\"custom-train\",\n",
    "        optimizer=torch.optim.RMSprop,\n",
    "        optimizer_kwargs=dict(lr=0.0001),\n",
    "        batch_size=16,\n",
    "        dataloader_cfg=dict(\n",
    "            shuffle=True,\n",
    "            num_workers=0,\n",
    "            drop_last=False,\n",
    "        ),\n",
    "        print_loss_interval=100,\n",
    "        checkpoint_interval=1000,\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is for training a \"real\" demo model\n",
    "CFG_DEMO: ConfigHolder = ConfigHolder.get_config_multisource(\n",
    "    cfg_names=(\"demo-g6-n10K-a_dfs-h92077\", \"tiny-v1\", \"sweep-v1\"),\n",
    ")\n",
    "\n",
    "# this is smaller, for testing\n",
    "CFG_TEST: ConfigHolder = ConfigHolder.get_config_multisource(\n",
    "    cfg_names=(\"demo_small-g3-n100-a_dfs-h69818\", \"nano-v1\", \"test-v1\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here is where to specify which config to actually use\n",
    "CFG: ConfigHolder = CFG_DEMO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"name\": \"multsrc_demo-g6-n10K-a_dfs-h92077_tiny-v1_sweep-v1\",\n",
      "  \"dataset_cfg\": {\n",
      "    \"name\": \"demo\",\n",
      "    \"fname\": \"demo-g6-n10K-a_dfs-h92077\",\n",
      "    \"sdc_hash\": 65001276129750023809936129568423056416231185113961566638389670113962440292077,\n",
      "    \"seed\": 42,\n",
      "    \"seq_len_min\": 1,\n",
      "    \"seq_len_max\": 512,\n",
      "    \"padding_token_index\": 10,\n",
      "    \"token_arr_joined\": \"<ADJLIST_START> <ADJLIST_END> <TARGET_START> <TARGET_END> <ORIGIN_START> <ORIGIN_END> <PATH_START> <PATH_END> <--> ; <PADDING> (0,0) (0,1) (1,0) (1,1) (0,2) (2,0) (1,2) (2,1) (2,2) (0,3) (3,0) (3,1) (2,3) (3,2) (1,3) (3,3) (0,4) (2,4) (4,0) (1,4) (4,1) (4,2) (3,4) (4,3) (4,4) (0,5) (5,0) (5,1) (2,5) (5,2) (5,3) (4,5) (5,4) (1,5) (3,5) (5,5)\",\n",
      "    \"applied_filters\": [],\n",
      "    \"grid_n\": 6,\n",
      "    \"grid_shape\": [\n",
      "      6,\n",
      "      6\n",
      "    ],\n",
      "    \"n_mazes\": 10000,\n",
      "    \"maze_ctor_name\": \"gen_dfs\",\n",
      "    \"maze_ctor_kwargs\": {}\n",
      "  },\n",
      "  \"model_cfg\": {\n",
      "    \"__format__\": \"BaseGPTConfig(SerializableDataclass)\",\n",
      "    \"name\": \"tiny-v1\",\n",
      "    \"act_fn\": \"gelu\",\n",
      "    \"d_model\": 32,\n",
      "    \"d_head\": 16,\n",
      "    \"n_layers\": 4,\n",
      "    \"weight_processing\": {\n",
      "      \"are_layernorms_folded\": false,\n",
      "      \"are_weights_processed\": false\n",
      "    }\n",
      "  },\n",
      "  \"train_cfg\": {\n",
      "    \"name\": \"sweep-v1\",\n",
      "    \"optimizer\": \"AdamW\",\n",
      "    \"optimizer_kwargs\": {\n",
      "      \"lr\": 0.0001\n",
      "    },\n",
      "    \"batch_size\": 64,\n",
      "    \"dataloader_cfg\": {\n",
      "      \"shuffle\": true,\n",
      "      \"num_workers\": 8,\n",
      "      \"persistent_workers\": true,\n",
      "      \"drop_last\": true\n",
      "    },\n",
      "    \"print_loss_interval\": 1000,\n",
      "    \"checkpoint_interval\": 5000\n",
      "  },\n",
      "  \"pretrainedtokenizer_kwargs\": null\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(json.dumps(CFG.summary(), indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading dataset from ../examples/demo-g6-n10K-a_dfs-h92077.zanj\n"
     ]
    }
   ],
   "source": [
    "# get just the dataset, generating it if needed. \n",
    "# This step can be skipped if you set `do_generate_dataset=True` when calling `train_model`\n",
    "# or if the dataset in question already exists\n",
    "\n",
    "# load the dataset from examples\n",
    "DATASET: MazeDataset = MazeDataset.from_config(CFG.dataset_cfg, verbose=True, local_base_path=PATH_EXAMPLES)\n",
    "# save it to the data directory where we will be saving our models\n",
    "DATASET.save(PATH_DATA / DATASET.cfg.to_fname())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-05-20 21:30:02 ERROR Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmiv\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>f:\\KNC\\maze-transformer\\notebooks\\wandb\\run-20230520_213005-2zg1fis5</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/miv/demo-notebooks/runs/2zg1fis5\" target=\"_blank\">fine-resonance-25</a></strong> to <a href=\"https://wandb.ai/miv/demo-notebooks\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-05-20 21:30:06 INFO config ={'__format__': 'ConfigHolder(SerializableDataclass)', 'dataset_cfg': {'__format__': 'MazeDatasetConfig(SerializableDataclass)', 'name': 'demo', 'dtype': 'torch.int16', 'seq_len_min': 1, 'seq_len_max': 512, 'seed': 42, 'applied_filters': [], 'grid_n': 6, 'n_mazes': 10000, 'maze_ctor': {'__name__': 'gen_dfs', '__module__': 'maze_transformer.generation.generators', '__doc__': ['generate a lattice maze using depth first search, iterative', '', '        # Arguments', '        - `grid_shape: Coord`: the shape of the grid', '        - `lattice_dim: int`: the dimension of the lattice', '          (default: `2`)', '        - `n_accessible_cells: int | None`: the number of accessible cells in the maze. If `None`, defaults to the total number of cells in the grid.', '            (default: `None`)', '        - `max_tree_depth: int | None`: the maximum depth of the tree. If `None`, defaults to `2 * n_accessible_cells`.', '            (default: `None`)', '        - `start_coord: Coord | None`: the starting coordinate of the generation algorithm. If `None`, defaults to a random coordinate.', '', '', '        # algorithm', '        1. Choose the initial cell, mark it as visited and push it to the stack', '        2. While the stack is not empty', '                1. Pop a cell from the stack and make it a current cell', '                2. If the current cell has any neighbours which have not been visited', '                        1. Push the current cell to the stack', '                        2. Choose one of the unvisited neighbours', '                        3. Remove the wall between the current cell and the chosen cell', '                        4. Mark the chosen cell as visited and push it to the stack', '        '], 'source_code': ['    @staticmethod', '    def gen_dfs(', '        grid_shape: Coord,', '        lattice_dim: int = 2,', '        n_accessible_cells: int | None = None,', '        max_tree_depth: int | None = None,', '        start_coord: Coord | None = None,', '    ) -> LatticeMaze:', '        \"\"\"generate a lattice maze using depth first search, iterative', '', '        # Arguments', '        - `grid_shape: Coord`: the shape of the grid', '        - `lattice_dim: int`: the dimension of the lattice', '          (default: `2`)', '        - `n_accessible_cells: int | None`: the number of accessible cells in the maze. If `None`, defaults to the total number of cells in the grid.', '            (default: `None`)', '        - `max_tree_depth: int | None`: the maximum depth of the tree. If `None`, defaults to `2 * n_accessible_cells`.', '            (default: `None`)', '        - `start_coord: Coord | None`: the starting coordinate of the generation algorithm. If `None`, defaults to a random coordinate.', '', '', '        # algorithm', '        1. Choose the initial cell, mark it as visited and push it to the stack', '        2. While the stack is not empty', '                1. Pop a cell from the stack and make it a current cell', '                2. If the current cell has any neighbours which have not been visited', '                        1. Push the current cell to the stack', '                        2. Choose one of the unvisited neighbours', '                        3. Remove the wall between the current cell and the chosen cell', '                        4. Mark the chosen cell as visited and push it to the stack', '        \"\"\"', '', '        # Default values if no constraints have been passed', '        grid_shape: Coord = np.array(grid_shape)', '        n_total_cells: int = int(np.prod(grid_shape))', '        if n_accessible_cells is None:', '            n_accessible_cells = n_total_cells', '        if max_tree_depth is None:', '            max_tree_depth = (', '                2 * n_total_cells', '            )  # We define max tree depth counting from the start coord in two directions. Therefore we divide by two in the if clause for neighboring sites later and multiply by two here.', '        if start_coord is None:', '            start_coord: Coord = np.random.randint(', '                0,', '                np.maximum(grid_shape - 1, 1),', '                size=2,', '            )', '        else:', '            start_coord = np.array(start_coord)', '', '        # initialize the maze with no connections', '        connection_list: ConnectionList = np.zeros(', '            (lattice_dim, grid_shape[0], grid_shape[1]), dtype=np.bool_', '        )', '', '        # initialize the stack with the target coord', '        visited_cells: set[tuple[int, int]] = set()', '        visited_cells.add(tuple(start_coord))', '        stack: list[Coord] = [start_coord]', '', '        # initialize tree_depth_counter', '        current_tree_depth: int = 1', '', '        # loop until the stack is empty or n_connected_cells is reached', '        while stack and (len(visited_cells) < n_accessible_cells):', '            # get the current coord from the stack', '            current_coord: Coord = stack.pop()', '', '            # filter neighbors by being within grid bounds and being unvisited', '            unvisited_neighbors_deltas: list[tuple[Coord, Coord]] = [', '                (neighbor, delta)', '                for neighbor, delta in zip(', '                    current_coord + NEIGHBORS_MASK, NEIGHBORS_MASK', '                )', '                if (', '                    (tuple(neighbor) not in visited_cells)', '                    and (0 <= neighbor[0] < grid_shape[0])', '                    and (0 <= neighbor[1] < grid_shape[1])', '                )', '            ]', '', \"            # don't continue if max_tree_depth/2 is already reached (divide by 2 because we can branch to multiple directions)\", '            if unvisited_neighbors_deltas and (', '                current_tree_depth <= max_tree_depth / 2', '            ):', '                stack.append(current_coord)', '', '                # choose one of the unvisited neighbors', '                chosen_neighbor, delta = random.choice(unvisited_neighbors_deltas)', '', '                # add connection', '                dim: int = np.argmax(np.abs(delta))', '                # if positive, down/right from current coord', '                # if negative, up/left from current coord (down/right from neighbor)', '                clist_node: Coord = (', '                    current_coord if (delta.sum() > 0) else chosen_neighbor', '                )', '                connection_list[dim, clist_node[0], clist_node[1]] = True', '', '                # add to visited cells and stack', '                visited_cells.add(tuple(chosen_neighbor))', '                stack.append(chosen_neighbor)', '', '                # Update current tree depth', '                current_tree_depth += 1', '            else:', '                current_tree_depth -= 1', '', '        return LatticeMaze(', '            connection_list=connection_list,', '            generation_meta=dict(', '                func_name=\"gen_dfs\",', '                grid_shape=grid_shape,', '                start_coord=start_coord,', '                visited_cells={tuple(int(x) for x in coord) for coord in visited_cells},', '                n_accessible_cells=int(n_accessible_cells),', '                max_tree_depth=int(max_tree_depth),', '                fully_connected=bool(len(visited_cells) == n_accessible_cells),', '            ),', '        )']}, 'maze_ctor_kwargs': {}, 'padding_token_index': 10, 'token_arr': ['<ADJLIST_START>', '<ADJLIST_END>', '<TARGET_START>', '<TARGET_END>', '<ORIGIN_START>', '<ORIGIN_END>', '<PATH_START>', '<PATH_END>', '<-->', ';', '<PADDING>', '(0,0)', '(0,1)', '(1,0)', '(1,1)', '(0,2)', '(2,0)', '(1,2)', '(2,1)', '(2,2)', '(0,3)', '(3,0)', '(3,1)', '(2,3)', '(3,2)', '(1,3)', '(3,3)', '(0,4)', '(2,4)', '(4,0)', '(1,4)', '(4,1)', '(4,2)', '(3,4)', '(4,3)', '(4,4)', '(0,5)', '(5,0)', '(5,1)', '(2,5)', '(5,2)', '(5,3)', '(4,5)', '(5,4)', '(1,5)', '(3,5)', '(5,5)'], 'tokenizer_map': {'<ADJLIST_START>': 0, '<ADJLIST_END>': 1, '<TARGET_START>': 2, '<TARGET_END>': 3, '<ORIGIN_START>': 4, '<ORIGIN_END>': 5, '<PATH_START>': 6, '<PATH_END>': 7, '<-->': 8, ';': 9, '<PADDING>': 10, '(0,0)': 11, '(0,1)': 12, '(1,0)': 13, '(1,1)': 14, '(0,2)': 15, '(2,0)': 16, '(1,2)': 17, '(2,1)': 18, '(2,2)': 19, '(0,3)': 20, '(3,0)': 21, '(3,1)': 22, '(2,3)': 23, '(3,2)': 24, '(1,3)': 25, '(3,3)': 26, '(0,4)': 27, '(2,4)': 28, '(4,0)': 29, '(1,4)': 30, '(4,1)': 31, '(4,2)': 32, '(3,4)': 33, '(4,3)': 34, '(4,4)': 35, '(0,5)': 36, '(5,0)': 37, '(5,1)': 38, '(2,5)': 39, '(5,2)': 40, '(5,3)': 41, '(4,5)': 42, '(5,4)': 43, '(1,5)': 44, '(3,5)': 45, '(5,5)': 46}, 'grid_shape': (6, 6), 'token_node_map': {'(0,0)': (0, 0), '(0,1)': (0, 1), '(1,0)': (1, 0), '(1,1)': (1, 1), '(0,2)': (0, 2), '(2,0)': (2, 0), '(1,2)': (1, 2), '(2,1)': (2, 1), '(2,2)': (2, 2), '(0,3)': (0, 3), '(3,0)': (3, 0), '(3,1)': (3, 1), '(2,3)': (2, 3), '(3,2)': (3, 2), '(1,3)': (1, 3), '(3,3)': (3, 3), '(0,4)': (0, 4), '(2,4)': (2, 4), '(4,0)': (4, 0), '(1,4)': (1, 4), '(4,1)': (4, 1), '(4,2)': (4, 2), '(3,4)': (3, 4), '(4,3)': (4, 3), '(4,4)': (4, 4), '(0,5)': (0, 5), '(5,0)': (5, 0), '(5,1)': (5, 1), '(2,5)': (2, 5), '(5,2)': (5, 2), '(5,3)': (5, 3), '(4,5)': (4, 5), '(5,4)': (5, 4), '(1,5)': (1, 5), '(3,5)': (3, 5), '(5,5)': (5, 5)}, 'n_tokens': 47}, 'model_cfg': {'__format__': 'BaseGPTConfig(SerializableDataclass)', 'name': 'tiny-v1', 'act_fn': 'gelu', 'd_model': 32, 'd_head': 16, 'n_layers': 4, 'weight_processing': {'are_layernorms_folded': False, 'are_weights_processed': False}}, 'train_cfg': {'__format__': 'TrainConfig(SerializableDataclass)', 'name': 'sweep-v1', 'optimizer': 'AdamW', 'optimizer_kwargs': {'lr': 0.0001}, 'batch_size': 64, 'dataloader_cfg': {'shuffle': True, 'num_workers': 8, 'persistent_workers': True, 'drop_last': True}, 'print_loss_interval': 1000, 'checkpoint_interval': 5000}, 'name': 'multsrc_demo-g6-n10K-a_dfs-h92077_tiny-v1_sweep-v1', 'pretrainedtokenizer_kwargs': None}\n",
      "2023-05-20 21:30:06 INFO Initialized logger\n",
      "2023-05-20 21:30:06 INFO Summary logged, getting dataset\n",
      "loading dataset from ../examples/demo-g6-n10K-a_dfs-h92077.zanj\n",
      "2023-05-20 21:30:29 INFO finished getting dataset\n",
      "2023-05-20 21:30:29 INFO Loaded 10000 sequences\n",
      "2023-05-20 21:30:29 INFO Creating dataloader\n",
      "2023-05-20 21:30:29 INFO finished dataloader, passing to train()\n",
      "2023-05-20 21:30:29 INFO Initializing model\n",
      "2023-05-20 21:30:29 INFO Initializing optimizer\n",
      "2023-05-20 21:30:29 INFO Starting training\n",
      "2023-05-20 21:30:29 INFO will train for 156 batches, checkpoint_interval_iters = 78, loss_interval_iters = 15\n",
      "2023-05-20 21:31:11 INFO iteration 0/156: loss=4.483\n",
      "2023-05-20 21:31:11 INFO Saving model to ../examples/multsrc_demo-g6-n10K-a_dfs-h92077_tiny-v1_sweep-v1_2023-05-20-21-30-02/checkpoints/model.iter_0.zanj\n",
      "2023-05-20 21:31:28 INFO iteration 15/156: loss=3.900\n",
      "2023-05-20 21:31:43 INFO iteration 30/156: loss=3.565\n",
      "2023-05-20 21:31:57 INFO iteration 45/156: loss=3.393\n",
      "2023-05-20 21:32:13 INFO iteration 60/156: loss=3.230\n",
      "2023-05-20 21:32:29 INFO iteration 75/156: loss=3.142\n",
      "2023-05-20 21:32:32 INFO Saving model to ../examples/multsrc_demo-g6-n10K-a_dfs-h92077_tiny-v1_sweep-v1_2023-05-20-21-30-02/checkpoints/model.iter_78.zanj\n",
      "2023-05-20 21:32:46 INFO iteration 90/156: loss=3.086\n",
      "2023-05-20 21:33:02 INFO iteration 105/156: loss=3.026\n",
      "2023-05-20 21:33:17 INFO iteration 120/156: loss=3.034\n",
      "2023-05-20 21:33:32 INFO iteration 135/156: loss=2.986\n",
      "2023-05-20 21:33:48 INFO iteration 150/156: loss=2.949\n",
      "2023-05-20 21:33:53 INFO Saving final model to ../examples/multsrc_demo-g6-n10K-a_dfs-h92077_tiny-v1_sweep-v1_2023-05-20-21-30-02/model.final.zanj\n",
      "2023-05-20 21:33:53 INFO Done!\n"
     ]
    }
   ],
   "source": [
    "result: TrainingResult = train_model(\n",
    "\tbase_path=PATH_DATA,\n",
    "    cfg=CFG,\n",
    "\twandb_project=WandbProject.DEMO_NOTEBOOKS,\n",
    "\tdo_generate_dataset=False,\n",
    "\tdataset_verbose=True,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "maze-transformer",
   "language": "python",
   "name": "maze-transformer"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
