{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "collapsed": false,
                "pycharm": {
                    "name": "#%%\n"
                }
            },
            "outputs": [],
            "source": [
                "# Generic\n",
                "import typing\n",
                "import os\n",
                "from pathlib import Path\n",
                "import typing\n",
                "import html\n",
                "\n",
                "# Plotting\n",
                "import matplotlib.pyplot as plt\n",
                "\n",
                "# Numerical Computing\n",
                "import numpy as np\n",
                "import torch\n",
                "import pandas as pd\n",
                "# Utilities\n",
                "from muutils.statcounter import StatCounter\n",
                "\n",
                "# Our Code\n",
                "from maze_transformer.utils.notebook_utils import configure_notebook\n",
                "from maze_transformer.generation.lattice_maze import LatticeMaze, SolvedMaze\n",
                "from maze_transformer.evaluation.plot_maze import PathFormat, MazePlot\n",
                "from maze_transformer.training.maze_dataset import MazeDataset, MazeDatasetConfig\n",
                "from maze_transformer.evaluation.eval_model import (\n",
                "    load_model_with_configs,\n",
                "    predict_maze_paths,\n",
                "    evaluate_model\n",
                ")\n",
                "from maze_transformer.evaluation.baseline_models import RandomBaseline\n",
                "from maze_transformer.evaluation.path_evals import (\n",
                "    PathEvals,\n",
                "    PathEvalFunction,\n",
                ")\n",
                "\n",
                "from maze_transformer.utils.utils import set_reproducibility, chunks, get_checkpoint_paths_for_run"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "collapsed": false,
                "pycharm": {
                    "name": "#%%\n"
                }
            },
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "Finishing last run (ID:7ru5xca7) before initializing another..."
                        ],
                        "text/plain": [
                            "<IPython.core.display.HTML object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/html": [
                            "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
                        ],
                        "text/plain": [
                            "<IPython.core.display.HTML object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "caae2aadb48b445fa8153c8e5b83815e",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/html": [
                            " View run <strong style=\"color:#cdcd00\">rare-blaze-57</strong> at: <a href='https://wandb.ai/aisc-search/understanding-search/runs/7ru5xca7' target=\"_blank\">https://wandb.ai/aisc-search/understanding-search/runs/7ru5xca7</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
                        ],
                        "text/plain": [
                            "<IPython.core.display.HTML object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/html": [
                            "Find logs at: <code>./wandb/run-20230421_152926-7ru5xca7/logs</code>"
                        ],
                        "text/plain": [
                            "<IPython.core.display.HTML object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/html": [
                            "Successfully finished last run (ID:7ru5xca7). Initializing new run:<br/>"
                        ],
                        "text/plain": [
                            "<IPython.core.display.HTML object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "a5b2538913904f4e98273a4750261b39",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01668119935008387, max=1.0)…"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/html": [
                            "wandb version 0.15.0 is available!  To upgrade, please run:\n",
                            " $ pip install wandb --upgrade"
                        ],
                        "text/plain": [
                            "<IPython.core.display.HTML object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/html": [
                            "Tracking run with wandb version 0.13.11"
                        ],
                        "text/plain": [
                            "<IPython.core.display.HTML object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/html": [
                            "Run data is saved locally in <code>/Users/dan/active_projects/understanding-search/maze-transformer/notebooks/wandb/run-20230421_153226-w2qxiqlo</code>"
                        ],
                        "text/plain": [
                            "<IPython.core.display.HTML object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/html": [
                            "Syncing run <strong><a href='https://wandb.ai/aisc-search/understanding-search/runs/w2qxiqlo' target=\"_blank\">wandering-violet-58</a></strong> to <a href='https://wandb.ai/aisc-search/understanding-search' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
                        ],
                        "text/plain": [
                            "<IPython.core.display.HTML object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/html": [
                            " View project at <a href='https://wandb.ai/aisc-search/understanding-search' target=\"_blank\">https://wandb.ai/aisc-search/understanding-search</a>"
                        ],
                        "text/plain": [
                            "<IPython.core.display.HTML object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "text/html": [
                            " View run at <a href='https://wandb.ai/aisc-search/understanding-search/runs/w2qxiqlo' target=\"_blank\">https://wandb.ai/aisc-search/understanding-search/runs/w2qxiqlo</a>"
                        ],
                        "text/plain": [
                            "<IPython.core.display.HTML object>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "2023-04-21 15:32:32 INFO config ={'__format__': 'ConfigHolder(SerializableDataclass)', 'dataset_cfg': {'__format__': 'MazeDatasetConfig(SerializableDataclass)', 'name': 'test', 'device': 'cpu', 'dtype': 'torch.int16', 'seq_len_min': 1, 'seq_len_max': 512, 'seed': 42, 'applied_filters': [], 'grid_n': 3, 'n_mazes': 5, 'maze_ctor': {'__name__': 'gen_dfs', '__module__': 'maze_transformer.generation.generators', '__doc__': ['generate a lattice maze using depth first search, iterative', '', '        algorithm:', '        1. Choose the initial cell, mark it as visited and push it to the stack', '        2. While the stack is not empty', '                1. Pop a cell from the stack and make it a current cell', '                2. If the current cell has any neighbours which have not been visited', '                        1. Push the current cell to the stack', '                        2. Choose one of the unvisited neighbours', '                        3. Remove the wall between the current cell and the chosen cell', '                        4. Mark the chosen cell as visited and push it to the stack', '        '], 'source_code': ['    @staticmethod', '    def gen_dfs(', '        grid_shape: Coord,', '        lattice_dim: int = 2,', '    ) -> LatticeMaze:', '        \"\"\"generate a lattice maze using depth first search, iterative', '', '        algorithm:', '        1. Choose the initial cell, mark it as visited and push it to the stack', '        2. While the stack is not empty', '                1. Pop a cell from the stack and make it a current cell', '                2. If the current cell has any neighbours which have not been visited', '                        1. Push the current cell to the stack', '                        2. Choose one of the unvisited neighbours', '                        3. Remove the wall between the current cell and the chosen cell', '                        4. Mark the chosen cell as visited and push it to the stack', '        \"\"\"', '', '        grid_shape = np.array(grid_shape)', '', '        # initialize the maze with no connections', '        connection_list: ConnectionList = np.zeros(', '            (lattice_dim, grid_shape[0], grid_shape[1]), dtype=np.bool_', '        )', '        start_coord: Coord = np.random.randint(', '            0,', '            np.maximum(grid_shape - 1, 1),', '            size=2,', '        )', '', '        # initialize the stack with the target coord', '        visited_cells: set[tuple[int, int]] = set()', '        visited_cells.add(tuple(start_coord))', '        stack: list[Coord] = [start_coord]', '', '        # loop until the stack is empty', '        while stack:', '            # get the current coord from the stack', '            current_coord: Coord = stack.pop()', '', '            # filter neighbors by being within grid bounds and being unvisited', '            unvisited_neighbors_deltas: list[tuple[Coord, Coord]] = [', '                (neighbor, delta)', '                for neighbor, delta in zip(', '                    current_coord + NEIGHBORS_MASK, NEIGHBORS_MASK', '                )', '                if (', '                    (tuple(neighbor) not in visited_cells)', '                    and (0 <= neighbor[0] < grid_shape[0])', '                    and (0 <= neighbor[1] < grid_shape[1])', '                )', '            ]', '', '            if unvisited_neighbors_deltas:', '                stack.append(current_coord)', '', '                # choose one of the unvisited neighbors', '                chosen_neighbor, delta = random.choice(unvisited_neighbors_deltas)', '', '                # add connection', '                dim: int = np.argmax(np.abs(delta))', '                # if positive, down/right from current coord', '                # if negative, up/left from current coord (down/right from neighbor)', '                clist_node: Coord = (', '                    current_coord if (delta.sum() > 0) else chosen_neighbor', '                )', '                connection_list[dim, clist_node[0], clist_node[1]] = True', '', '                # add to visited cells and stack', '                visited_cells.add(tuple(chosen_neighbor))', '                stack.append(chosen_neighbor)', '', '        return LatticeMaze(', '            connection_list=connection_list,', '            generation_meta=dict(', '                func_name=\"gen_dfs\",', '                grid_shape=grid_shape,', '                start_coord=start_coord,', '            ),', '        )']}, 'padding_token_index': 10, 'token_arr': ['<ADJLIST_START>', '<ADJLIST_END>', '<TARGET_START>', '<TARGET_END>', '<ORIGIN_START>', '<ORIGIN_END>', '<PATH_START>', '<PATH_END>', '<-->', ';', '<PADDING>', '(0,0)', '(0,1)', '(0,2)', '(1,0)', '(1,1)', '(1,2)', '(2,0)', '(2,1)', '(2,2)'], 'tokenizer_map': {'<ADJLIST_START>': 0, '<ADJLIST_END>': 1, '<TARGET_START>': 2, '<TARGET_END>': 3, '<ORIGIN_START>': 4, '<ORIGIN_END>': 5, '<PATH_START>': 6, '<PATH_END>': 7, '<-->': 8, ';': 9, '<PADDING>': 10, '(0,0)': 11, '(0,1)': 12, '(0,2)': 13, '(1,0)': 14, '(1,1)': 15, '(1,2)': 16, '(2,0)': 17, '(2,1)': 18, '(2,2)': 19}, 'grid_shape': (3, 3), 'token_node_map': {'(0,0)': (0, 0), '(0,1)': (0, 1), '(0,2)': (0, 2), '(1,0)': (1, 0), '(1,1)': (1, 1), '(1,2)': (1, 2), '(2,0)': (2, 0), '(2,1)': (2, 1), '(2,2)': (2, 2)}, 'n_tokens': 20}, 'model_cfg': {'__format__': 'BaseGPTConfig(SerializableDataclass)', 'name': 'tiny-v1', 'act_fn': 'gelu', 'd_model': 32, 'd_head': 16, 'n_layers': 4, 'are_layernorms_folded': False, 'are_weights_processed': False}, 'train_cfg': {'__format__': 'TrainConfig(SerializableDataclass)', 'name': 'tiny-v1', 'optimizer': 'RMSprop', 'optimizer_kwargs': {'lr': 1e-06}, 'batch_size': 5, 'dataloader_cfg': {'shuffle': True, 'num_workers': 8, 'persistent_workers': True, 'drop_last': True}, 'print_loss_interval': 1000, 'checkpoint_interval': 5000}, 'name': 'default', 'pretrainedtokenizer_kwargs': None}\n",
                        "2023-04-21 15:32:32 INFO Loaded 5 sequences\n",
                        "2023-04-21 15:32:32 INFO Creating dataloader\n",
                        "2023-04-21 15:32:32 INFO Initializing model\n",
                        "2023-04-21 15:32:32 INFO Initializing optimizer\n",
                        "2023-04-21 15:32:32 INFO Starting training\n"
                    ]
                },
                {
                    "ename": "RuntimeError",
                    "evalue": "element 0 of tensors does not require grad and does not have a grad_fn",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
                        "Cell \u001b[0;32mIn[16], line 27\u001b[0m\n\u001b[1;32m     20\u001b[0m logger: WandbLogger \u001b[39m=\u001b[39m WandbLogger\u001b[39m.\u001b[39mcreate(\n\u001b[1;32m     21\u001b[0m \tconfig\u001b[39m=\u001b[39mconfig_holder\u001b[39m.\u001b[39mserialize(),\n\u001b[1;32m     22\u001b[0m \tproject\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39munderstanding-search\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     23\u001b[0m \tjob_type\u001b[39m=\u001b[39mWandbJobType\u001b[39m.\u001b[39mTRAIN_MODEL,\n\u001b[1;32m     24\u001b[0m )\n\u001b[1;32m     25\u001b[0m dataloader \u001b[39m=\u001b[39m get_dataloader(dataset, config_holder, logger)\n\u001b[0;32m---> 27\u001b[0m trained_model \u001b[39m=\u001b[39m train(\n\u001b[1;32m     28\u001b[0m \tcfg\u001b[39m=\u001b[39;49mconfig_holder,\n\u001b[1;32m     29\u001b[0m \tdataloader\u001b[39m=\u001b[39;49mdataloader,\n\u001b[1;32m     30\u001b[0m \tlogger\u001b[39m=\u001b[39;49mlogger,\n\u001b[1;32m     31\u001b[0m \toutput_dir\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m./data/test\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m     32\u001b[0m \tdevice\u001b[39m=\u001b[39;49mdevice,\n\u001b[1;32m     33\u001b[0m )\n",
                        "File \u001b[0;32m~/active_projects/understanding-search/maze-transformer/maze_transformer/training/training.py:105\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(cfg, dataloader, logger, output_dir, device, zanj)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[39mfor\u001b[39;00m iteration, batch \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(dataloader):\n\u001b[1;32m     98\u001b[0m     \u001b[39m# compute loss\u001b[39;00m\n\u001b[1;32m     99\u001b[0m     \u001b[39m# batch_on_device: Int[torch.Tensor, \"batch sequence\"] = batch.type(\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    102\u001b[0m \n\u001b[1;32m    103\u001b[0m     \u001b[39m# loss: Loss = model(batch_on_device[:, :-1], return_type=\"loss\")\u001b[39;00m\n\u001b[1;32m    104\u001b[0m     loss: Loss \u001b[39m=\u001b[39m model(batch, return_type\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mloss\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 105\u001b[0m     loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m    107\u001b[0m     optimizer\u001b[39m.\u001b[39mstep()\n\u001b[1;32m    108\u001b[0m     optimizer\u001b[39m.\u001b[39mzero_grad()\n",
                        "File \u001b[0;32m~/active_projects/understanding-search/maze-transformer/.venv/lib/python3.10/site-packages/torch/_tensor.py:488\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    479\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    480\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    481\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    486\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m    487\u001b[0m     )\n\u001b[0;32m--> 488\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[1;32m    489\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[1;32m    490\u001b[0m )\n",
                        "File \u001b[0;32m~/active_projects/understanding-search/maze-transformer/.venv/lib/python3.10/site-packages/torch/autograd/__init__.py:197\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    192\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    194\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    195\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    196\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 197\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    198\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    199\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
                        "\u001b[0;31mRuntimeError\u001b[0m: element 0 of tensors does not require grad and does not have a grad_fn"
                    ]
                }
            ],
            "source": [
                "# Setup\n",
                "device = configure_notebook(seed=42, dark_mode=True)\n",
                "\n",
                "# We won't be training any models\n",
                "torch.set_grad_enabled(False)\n",
                "\n",
                "# Get latest model\n",
                "# this should point towards a directory containing a run. \n",
                "# If you don't have any runs, you can create a dataset with `poetry run python scripts/create_dataset.py create ./data/maze 10 --grid_n=4`\n",
                "# Then train a model with `poetry run python scripts/train_model.py ./data/maze/g4-n10`\n",
                "run_path = Path(\"../examples/maze/g4-n10/g4-n10_tiny-v1_2023-03-28-22-44-54\")\n",
                "\n",
                "assert run_path.exists(), f\"Run path {run_path.as_posix()} does not exist\"\n",
                "model_path = list(sorted(run_path.glob(\"**/model.final.pt\"), key=os.path.getmtime))[\n",
                "\t-1\n",
                "].resolve()\n",
                "maze_path = run_path.parent / \"maze_tokens.jsonl\"\n",
                "\n",
                "dataset = MazeDataset.disk_load(run_path.parent, do_config=True, do_tokens=True)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "collapsed": false,
                "pycharm": {
                    "name": "#%% md\n"
                }
            },
            "source": [
                "# plot example mazes"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "collapsed": false,
                "pycharm": {
                    "name": "#%%\n"
                }
            },
            "outputs": [],
            "source": [
                "# setup consts\n",
                "def testdata_plot_predicted_path(\n",
                "\t\tmodel,\n",
                "\t\tmaze_tokens_path: Path, \n",
                "\t\tn_mazes: int = 10,\n",
                "\t\tmax_new_tokens: int = 8,\n",
                "\t):\n",
                "\t# load maze test data\n",
                "\tmazes_tokens: list[list[str]] = [\n",
                " \t   line.split() for line in maze_tokens_path.read_text().splitlines()\n",
                "\t]\n",
                "\tmazes_tokens = mazes_tokens[:n_mazes]\n",
                "\n",
                "\tsolved_mazes = [SolvedMaze.from_tokens(tokens, dataset.cfg) for tokens in mazes_tokens]\n",
                "\n",
                "\tpredictions = predict_maze_paths(\n",
                "\t\ttokens_batch=mazes_tokens,\n",
                "\t\tdata_cfg=dataset.cfg,\n",
                "\t\tmodel=model,\n",
                "\t\tmax_new_tokens=max_new_tokens,\n",
                "\t)\n",
                "\n",
                "\n",
                "\t# plot\n",
                "\tfor i, maze in enumerate(solved_mazes):\n",
                "\t\tMazePlot(maze).add_predicted_path(predictions[i]).plot()\n",
                "\t\tplt.show()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "model, cfg_holder = load_model_with_configs(model_path)\n",
                "testdata_plot_predicted_path(model, maze_path)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "baseline_model = RandomBaseline(cfg_holder)\n",
                "\n",
                "# Longest possible path in random DFS is NxN - 1\\n\n",
                "testdata_plot_predicted_path(baseline_model, maze_path, max_new_tokens=15)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "collapsed": false,
                "pycharm": {
                    "name": "#%% md\n"
                }
            },
            "source": [
                "# run path dist eval"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "collapsed": false,
                "pycharm": {
                    "name": "#%%\n"
                }
            },
            "outputs": [],
            "source": [
                "model_checkpoints = get_checkpoint_paths_for_run(model_path.parent)\n",
                "print(f\"Found {len(model_checkpoints)} checkpoints:\\n\\t{model_checkpoints = }\")\n",
                "\n",
                "pathdist_scores_idx: dict[int, dict[str, StatCounter]] = dict()\n",
                "\n",
                "for idx, checkpoint_path in model_checkpoints:\n",
                "\tprint(f\"# Evaluating checkpoint {idx} at {checkpoint_path}\")\n",
                "\tmodel, _ = load_model_with_configs(checkpoint_path)\n",
                "\tpathdist_scores_idx[idx] = evaluate_model(\n",
                "\t\tmodel=model,\n",
                "\t\tdataset=dataset\n",
                "\t)\n",
                "\n",
                "\n",
                "data = {\n",
                "\tname: {\n",
                "\t\tidx: scores[name]\n",
                "\t\tfor idx, scores in pathdist_scores_idx.items()\n",
                "\t}\n",
                "\tfor name in pathdist_scores_idx[0]\n",
                "}"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "collapsed": false,
                "pycharm": {
                    "name": "#%%\n"
                }
            },
            "outputs": [],
            "source": [
                "def plot_pathdist_scores(\n",
                "\t\tdata: dict[str, dict[int, StatCounter]],\n",
                "\t\tcolors: dict[str, str]|None = None,\n",
                "\t\tpercentile_bounds: tuple[float, float] = (0.4, 0.6),\n",
                "\t):\n",
                "\n",
                "\tif colors is None:\n",
                "\t\tcolors = {\n",
                "\t\t\tfunc_name: f\"C{i}\"\n",
                "\t\t\tfor i, func_name in enumerate(data.keys())\n",
                "\t\t}\n",
                "\n",
                "\tfig, ax = plt.subplots(len(data), 1, figsize = (8, 4 * len(data)))\n",
                "\tfig.subplots_adjust(hspace = 0.5)\n",
                "\t\t\n",
                "\tfor i, (name, scores_indexed) in enumerate(data.items()):\n",
                "\t\tx = list(scores_indexed.keys())\n",
                "\t\ty = [\n",
                "\t\t\tscores_indexed[i].median()\n",
                "\t\t\tfor i in x\n",
                "\t\t]\n",
                "\t\tax[i].plot(x, y, label=name, color=colors[name])\n",
                "\t\t# plot shaded error bars\n",
                "\t\ty_ub = [\n",
                "\t\t\tscores_indexed[i].percentile(percentile_bounds[1])\n",
                "\t\t\tfor i in x\n",
                "\t\t]\n",
                "\t\ty_lb = [\n",
                "\t\t\tscores_indexed[i].percentile(percentile_bounds[0])\n",
                "\t\t\tfor i in x\n",
                "\t\t]\n",
                "\t\tax[i].fill_between(\n",
                "\t\t\tx, y_lb, y_ub,\n",
                "\t    \talpha=0.5, \n",
                "\t\t\tedgecolor=colors[name], facecolor=colors[name],\n",
                "\t\t)\n",
                "\n",
                "\t\tax[i].set_title(f\"{name}, {percentile_bounds = }\")\n",
                "\t\tax[i].set_xlabel(\"Checkpoint\")\n",
                "\t\tax[i].set_ylabel(\"score\")\n",
                "\n",
                "\tplt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "collapsed": false,
                "pycharm": {
                    "name": "#%%\n"
                }
            },
            "outputs": [],
            "source": [
                "plot_pathdist_scores(data)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": ".venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.10"
        },
        "orig_nbformat": 4
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
