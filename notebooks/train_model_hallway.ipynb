{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generic\n",
    "import typing\n",
    "import os\n",
    "from pathlib import Path\n",
    "import typing\n",
    "import json\n",
    "\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Numerical Computing\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# muutils\n",
    "from zanj.zanj import ZANJ, ZANJ_GLOBAL_DEFAULTS\n",
    "\n",
    "# Our Code\n",
    "from muutils.mlutils import configure_notebook\n",
    "from maze_transformer.training.config import ConfigHolder, ZanjHookedTransformer, BaseGPTConfig, TrainConfig\n",
    "from maze_dataset import MazeDataset, MazeDatasetConfig\n",
    "from maze_dataset.dataset.configs import MAZE_DATASET_CONFIGS\n",
    "from maze_dataset.generation import LatticeMazeGenerators\n",
    "from maze_transformer.training.train_model import TrainingResult, train_model\n",
    "from maze_transformer.training.wandb_logger import WandbProject\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set global defaults for ZANJ\n",
    "ZANJ_GLOBAL_DEFAULTS.external_array_threshold = 1024\n",
    "ZANJ_GLOBAL_DEFAULTS.external_list_threshold = 1024\n",
    "\n",
    "# paths\n",
    "PATH_EXAMPLES: Path = Path(\"../examples/\")\n",
    "PATH_DATA: Path = Path(\"../data/\")\n",
    "\n",
    "# reproducibility and device\n",
    "DEVICE = configure_notebook(seed=42, dark_mode=True)\n",
    "print(f\"{DEVICE = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{list(MAZE_DATASET_CONFIGS.keys()) = }\")\n",
    "\n",
    "# if you want to specify a custom config, you can do so here\n",
    "CFG_CUSTOM: ConfigHolder = ConfigHolder(\n",
    "    name = \"hallway-medium\",\n",
    "    dataset_cfg = MazeDatasetConfig(\n",
    "\t\tname=\"custom-hallway\",\n",
    "\t\tgrid_n=8,\n",
    "\t\tn_mazes=1000000,\n",
    "\t\tmaze_ctor=LatticeMazeGenerators.gen_dfs,\n",
    "        maze_ctor_kwargs=dict(\n",
    "            do_forks=False,\n",
    "        ),\n",
    "\t),\n",
    "    model_cfg = BaseGPTConfig(\n",
    "        name=\"custom-model\",\n",
    "        act_fn=\"gelu\",\n",
    "        d_model=128,\n",
    "        d_head=32,\n",
    "        n_layers=6,\n",
    "    ),\n",
    "    train_cfg = TrainConfig(\n",
    "        name=\"custom-train\",\n",
    "        optimizer=torch.optim.AdamW,\n",
    "        optimizer_kwargs=dict(lr=0.00001),\n",
    "        batch_size=32,\n",
    "        dataloader_cfg=dict(\n",
    "            shuffle=True,\n",
    "            num_workers=4,\n",
    "            drop_last=False,\n",
    "        ),\n",
    "        print_loss_interval=100,\n",
    "        checkpoint_interval=1000,\n",
    "    ),\n",
    ")\n",
    "\n",
    "CFG_TEST: ConfigHolder = ConfigHolder(\n",
    "        name = \"hallway-nano\",\n",
    "    dataset_cfg = MazeDatasetConfig(\n",
    "\t\tname=\"custom-hallway\",\n",
    "\t\tgrid_n=3,\n",
    "\t\tn_mazes=8,\n",
    "\t\tmaze_ctor=LatticeMazeGenerators.gen_dfs,\n",
    "        maze_ctor_kwargs=dict(\n",
    "            do_forks=False,\n",
    "        ),\n",
    "\t),\n",
    "    model_cfg = BaseGPTConfig(\n",
    "        name=\"custom-model\",\n",
    "        act_fn=\"gelu\",\n",
    "        d_model=8,\n",
    "        d_head=2,\n",
    "        n_layers=2,\n",
    "    ),\n",
    "    train_cfg = TrainConfig(\n",
    "        name=\"custom-train\",\n",
    "        optimizer=torch.optim.AdamW,\n",
    "        optimizer_kwargs=dict(lr=0.0001),\n",
    "        batch_size=4,\n",
    "        dataloader_cfg=dict(\n",
    "            shuffle=True,\n",
    "            drop_last=False,\n",
    "        ),\n",
    "        print_loss_interval=4,\n",
    "        checkpoint_interval=1000,\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here is where to specify which config to actually use\n",
    "CFG: ConfigHolder = CFG_TEST # change to CFG_CUSTOM to train a \"real\" model, the CFG_TEST is for CI testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(json.dumps(CFG.summary(), indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get just the dataset, generating it if needed. \n",
    "# This step can be skipped if you set `do_generate_dataset=True` when calling `train_model`\n",
    "# or if the dataset in question already exists\n",
    "\n",
    "# load the dataset\n",
    "DATASET: MazeDataset = MazeDataset.from_config(\n",
    "    CFG.dataset_cfg, \n",
    "    verbose=True, \n",
    "    load_local=False,\n",
    "    local_base_path=PATH_DATA,\n",
    ").filter_by.collect_generation_meta()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET.save(PATH_DATA / DATASET.cfg.to_fname())\n",
    "CFG.dataset_cfg = DATASET.cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result: TrainingResult = train_model(\n",
    "\tbase_path=PATH_DATA,\n",
    "    cfg=CFG,\n",
    "\twandb_project=WandbProject.INTEGRATION_TESTS, # change this to WandbProject.DEMO_NOTEBOOKS! INTEGRATION_TESTS is for CI testing\n",
    "\tdo_generate_dataset=False,\n",
    "\tdataset_verbose=True,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "maze-transformer",
   "language": "python",
   "name": "maze-transformer"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
