{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generic\n",
    "import typing\n",
    "import os\n",
    "from pathlib import Path\n",
    "import typing\n",
    "import json\n",
    "\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Numerical Computing\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# muutils\n",
    "from zanj.zanj import ZANJ, ZANJ_GLOBAL_DEFAULTS\n",
    "\n",
    "# Our Code\n",
    "from muutils.nbutils.configure_notebook import configure_notebook\n",
    "from maze_transformer.training.config import ConfigHolder, ZanjHookedTransformer, BaseGPTConfig, TrainConfig\n",
    "from maze_dataset import MazeDataset, MazeDatasetConfig\n",
    "from maze_dataset.dataset.configs import MAZE_DATASET_CONFIGS\n",
    "from maze_dataset.generation import LatticeMazeGenerators\n",
    "from maze_transformer.training.train_model import TrainingResult, train_model\n",
    "from maze_transformer.training.wandb_logger import WandbProject\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEVICE = device(type='cuda')\n"
     ]
    }
   ],
   "source": [
    "# set global defaults for ZANJ\n",
    "ZANJ_GLOBAL_DEFAULTS.external_array_threshold = 1024\n",
    "ZANJ_GLOBAL_DEFAULTS.external_list_threshold = 1024\n",
    "\n",
    "# paths\n",
    "PATH_EXAMPLES: Path = Path(\"../examples/\")\n",
    "PATH_DATA: Path = Path(\"../data/\")\n",
    "\n",
    "# reproducibility and device\n",
    "DEVICE = configure_notebook(seed=42, dark_mode=True)\n",
    "print(f\"{DEVICE = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list(MAZE_DATASET_CONFIGS.keys()) = ['test-g3-n5-a_dfs-h89001', 'demo_small-g3-n100-a_dfs-h58410', 'demo-g6-n10K-a_dfs-h86254']\n"
     ]
    }
   ],
   "source": [
    "print(f\"{list(MAZE_DATASET_CONFIGS.keys()) = }\")\n",
    "\n",
    "# if you want to specify a custom config, you can do so here\n",
    "CFG_CUSTOM: ConfigHolder = ConfigHolder(\n",
    "    name = \"hallway-medium\",\n",
    "    dataset_cfg = MazeDatasetConfig(\n",
    "\t\tname=\"custom-hallway\",\n",
    "\t\tgrid_n=8,\n",
    "\t\tn_mazes=100_000,\n",
    "\t\tmaze_ctor=LatticeMazeGenerators.gen_dfs,\n",
    "        maze_ctor_kwargs=dict(\n",
    "            do_forks=False,\n",
    "        ),\n",
    "\t),\n",
    "    model_cfg = BaseGPTConfig(\n",
    "        name=\"custom-model\",\n",
    "        act_fn=\"gelu\",\n",
    "        d_model=128,\n",
    "        d_head=32,\n",
    "        n_layers=6,\n",
    "    ),\n",
    "    train_cfg = TrainConfig(\n",
    "        name=\"custom-train\",\n",
    "        optimizer=torch.optim.AdamW,\n",
    "        optimizer_kwargs=dict(lr=0.00001),\n",
    "        batch_size=32,\n",
    "        dataloader_cfg=dict(\n",
    "            shuffle=True,\n",
    "            num_workers=4,\n",
    "            drop_last=False,\n",
    "        ),\n",
    "        intervals_count=dict(\n",
    "            print_loss=1000,\n",
    "            checkpoint=20,\n",
    "            eval_fast=100,\n",
    "            eval_slow=50,\n",
    "        ),\n",
    "        validation_dataset_cfg=10,\n",
    "    ),\n",
    ")\n",
    "\n",
    "CFG_TEST: ConfigHolder = ConfigHolder(\n",
    "        name = \"hallway-nano\",\n",
    "    dataset_cfg = MazeDatasetConfig(\n",
    "\t\tname=\"custom-hallway\",\n",
    "\t\tgrid_n=3,\n",
    "\t\tn_mazes=8,\n",
    "\t\tmaze_ctor=LatticeMazeGenerators.gen_dfs,\n",
    "        maze_ctor_kwargs=dict(\n",
    "            do_forks=False,\n",
    "        ),\n",
    "\t),\n",
    "    model_cfg = BaseGPTConfig(\n",
    "        name=\"custom-model\",\n",
    "        act_fn=\"gelu\",\n",
    "        d_model=8,\n",
    "        d_head=2,\n",
    "        n_layers=2,\n",
    "    ),\n",
    "    train_cfg = TrainConfig(\n",
    "        name=\"custom-train\",\n",
    "        optimizer=torch.optim.AdamW,\n",
    "        optimizer_kwargs=dict(lr=0.0001),\n",
    "        batch_size=4,\n",
    "        dataloader_cfg=dict(\n",
    "            shuffle=True,\n",
    "            drop_last=False,\n",
    "        ),\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here is where to specify which config to actually use\n",
    "CFG: ConfigHolder = CFG_CUSTOM # change to CFG_CUSTOM to train a \"real\" model, the CFG_TEST is for CI testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"name\": \"hallway-medium\",\n",
      "  \"dataset_cfg\": {\n",
      "    \"name\": \"custom-hallway\",\n",
      "    \"fname\": \"custom-hallway-g8-n100K-a_dfs-h31024\",\n",
      "    \"sdc_hash\": 43825844172657897425957296941560401936207458692340074698180715204853252031024,\n",
      "    \"seed\": 42,\n",
      "    \"seq_len_min\": 1,\n",
      "    \"seq_len_max\": 512,\n",
      "    \"padding_token_index\": 10,\n",
      "    \"token_arr_joined\": \"<ADJLIST_START> <ADJLIST_END> <TARGET_START> <TARGET_END> <ORIGIN_START> <ORIGIN_END> <PATH_START> <PATH_END> <--> ; <PADDING> (0,0) (0,1) (1,0) (1,1) (0,2) (2,0) (1,2) (2,1) (2,2) (0,3) (3,0) (3,1) (2,3) (3,2) (1,3) (3,3) (0,4) (2,4) (4,0) (1,4) (4,1) (4,2) (3,4) (4,3) (4,4) (0,5) (5,0) (5,1) (2,5) (5,2) (5,3) (4,5) (5,4) (1,5) (3,5) (5,5) (0,6) (2,6) (4,6) (6,0) (1,6) (6,1) (6,2) (3,6) (6,3) (6,4) (5,6) (6,5) (6,6) (0,7) (7,0) (7,1) (2,7) (7,2) (7,3) (4,7) (7,4) (7,5) (6,7) (7,6) (1,7) (3,7) (5,7) (7,7)\",\n",
      "    \"applied_filters\": [],\n",
      "    \"grid_n\": 8,\n",
      "    \"grid_shape\": [\n",
      "      8,\n",
      "      8\n",
      "    ],\n",
      "    \"n_mazes\": 100000,\n",
      "    \"maze_ctor_name\": \"gen_dfs\",\n",
      "    \"maze_ctor_kwargs\": {\n",
      "      \"do_forks\": false\n",
      "    }\n",
      "  },\n",
      "  \"model_cfg\": {\n",
      "    \"name\": \"custom-model\",\n",
      "    \"act_fn\": \"gelu\",\n",
      "    \"d_model\": 128,\n",
      "    \"d_head\": 32,\n",
      "    \"n_layers\": 6,\n",
      "    \"weight_processing\": {\n",
      "      \"are_layernorms_folded\": false,\n",
      "      \"are_weights_processed\": false\n",
      "    },\n",
      "    \"n_heads\": 4\n",
      "  },\n",
      "  \"train_cfg\": {\n",
      "    \"name\": \"custom-train\",\n",
      "    \"optimizer\": \"AdamW\",\n",
      "    \"optimizer_kwargs\": {\n",
      "      \"lr\": 1e-05\n",
      "    },\n",
      "    \"batch_size\": 32,\n",
      "    \"dataloader_cfg\": {\n",
      "      \"shuffle\": true,\n",
      "      \"num_workers\": 4,\n",
      "      \"drop_last\": false\n",
      "    },\n",
      "    \"intervals\": null,\n",
      "    \"intervals_count\": {\n",
      "      \"print_loss\": 1000,\n",
      "      \"checkpoint\": 20,\n",
      "      \"eval_fast\": 100,\n",
      "      \"eval_slow\": 50\n",
      "    },\n",
      "    \"evals_max_new_tokens\": 8,\n",
      "    \"validation_dataset_cfg\": 10\n",
      "  },\n",
      "  \"pretrainedtokenizer_kwargs\": null\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(json.dumps(CFG.summary(), indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seeing if we can download the dataset...\n",
      "no download found, or download failed\n",
      "generating dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "generating & solving mazes: 100%|██████████| 100000/100000 [03:35<00:00, 464.72maze/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving dataset to ..\\data\\custom-hallway-g8-n100K-a_dfs-h31024.zanj\n",
      "Got dataset custom-hallway with 100000 items. output.cfg.to_fname() = 'custom-hallway-g8-n100K-a_dfs-h31024'\n"
     ]
    }
   ],
   "source": [
    "# get just the dataset, generating it if needed. \n",
    "# This step can be skipped if you set `do_generate_dataset=True` when calling `train_model`\n",
    "# or if the dataset in question already exists\n",
    "\n",
    "# load the dataset\n",
    "DATASET: MazeDataset = MazeDataset.from_config(\n",
    "    CFG.dataset_cfg, \n",
    "    verbose=True, \n",
    "    load_local=False,\n",
    "    local_base_path=PATH_DATA,\n",
    ").filter_by.collect_generation_meta()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET.save(PATH_DATA / DATASET.cfg.to_fname())\n",
    "CFG.dataset_cfg = DATASET.cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-06-15 03:09:18 ERROR Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmiv\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>f:\\KNC\\maze-transformer\\notebooks\\wandb\\run-20230615_030920-mxwgv144</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/miv/demo-notebooks/runs/mxwgv144' target=\"_blank\">confused-sound-32</a></strong> to <a href='https://wandb.ai/miv/demo-notebooks' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/miv/demo-notebooks' target=\"_blank\">https://wandb.ai/miv/demo-notebooks</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/miv/demo-notebooks/runs/mxwgv144' target=\"_blank\">https://wandb.ai/miv/demo-notebooks/runs/mxwgv144</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-06-15 03:09:21 INFO config ={'__format__': 'ConfigHolder(SerializableDataclass)', 'dataset_cfg': {'__format__': 'MazeDatasetConfig(SerializableDataclass)', 'name': 'custom-hallway', 'seq_len_min': 1, 'seq_len_max': 512, 'seed': 42, 'applied_filters': [{'name': 'collect_generation_meta', 'args': (), 'kwargs': {}}], 'grid_n': 8, 'n_mazes': 100000, 'maze_ctor': {'__name__': 'gen_dfs', '__module__': 'maze_dataset.generation.generators', '__doc__': ['generate a lattice maze using depth first search, iterative', '', '        # Arguments', '        - `grid_shape: Coord`: the shape of the grid', '        - `lattice_dim: int`: the dimension of the lattice', '          (default: `2`)', '        - `n_accessible_cells: int | None`: the number of accessible cells in the maze. If `None`, defaults to the total number of cells in the grid.', '            (default: `None`)', '        - `max_tree_depth: int | None`: the maximum depth of the tree. If `None`, defaults to `2 * n_accessible_cells`.', '            (default: `None`)', '        - `do_forks: bool`: whether to allow forks in the maze. If `False`, the maze will be have no forks and will be a simple hallway.', '        - `start_coord: Coord | None`: the starting coordinate of the generation algorithm. If `None`, defaults to a random coordinate.', '', '', '        # algorithm', '        1. Choose the initial cell, mark it as visited and push it to the stack', '        2. While the stack is not empty', '                1. Pop a cell from the stack and make it a current cell', '                2. If the current cell has any neighbours which have not been visited', '                        1. Push the current cell to the stack', '                        2. Choose one of the unvisited neighbours', '                        3. Remove the wall between the current cell and the chosen cell', '                        4. Mark the chosen cell as visited and push it to the stack', '        '], 'source_code': ['    @staticmethod', '    def gen_dfs(', '        grid_shape: Coord,', '        lattice_dim: int = 2,', '        n_accessible_cells: int | None = None,', '        max_tree_depth: int | None = None,', '        do_forks: bool = True,', '        start_coord: Coord | None = None,', '    ) -> LatticeMaze:', '        \"\"\"generate a lattice maze using depth first search, iterative', '', '        # Arguments', '        - `grid_shape: Coord`: the shape of the grid', '        - `lattice_dim: int`: the dimension of the lattice', '          (default: `2`)', '        - `n_accessible_cells: int | None`: the number of accessible cells in the maze. If `None`, defaults to the total number of cells in the grid.', '            (default: `None`)', '        - `max_tree_depth: int | None`: the maximum depth of the tree. If `None`, defaults to `2 * n_accessible_cells`.', '            (default: `None`)', '        - `do_forks: bool`: whether to allow forks in the maze. If `False`, the maze will be have no forks and will be a simple hallway.', '        - `start_coord: Coord | None`: the starting coordinate of the generation algorithm. If `None`, defaults to a random coordinate.', '', '', '        # algorithm', '        1. Choose the initial cell, mark it as visited and push it to the stack', '        2. While the stack is not empty', '                1. Pop a cell from the stack and make it a current cell', '                2. If the current cell has any neighbours which have not been visited', '                        1. Push the current cell to the stack', '                        2. Choose one of the unvisited neighbours', '                        3. Remove the wall between the current cell and the chosen cell', '                        4. Mark the chosen cell as visited and push it to the stack', '        \"\"\"', '', '        # Default values if no constraints have been passed', '        grid_shape: Coord = np.array(grid_shape)', '        n_total_cells: int = int(np.prod(grid_shape))', '        if n_accessible_cells is None:', '            n_accessible_cells = n_total_cells', '        if max_tree_depth is None:', '            max_tree_depth = (', '                2 * n_total_cells', '            )  # We define max tree depth counting from the start coord in two directions. Therefore we divide by two in the if clause for neighboring sites later and multiply by two here.', '', '        start_coord = _random_start_coord(grid_shape, start_coord)', '', '        # initialize the maze with no connections', '        connection_list: ConnectionList = np.zeros(', '            (lattice_dim, grid_shape[0], grid_shape[1]), dtype=np.bool_', '        )', '', '        # initialize the stack with the target coord', '        visited_cells: set[tuple[int, int]] = set()', '        visited_cells.add(tuple(start_coord))', '        stack: list[Coord] = [start_coord]', '', '        # initialize tree_depth_counter', '        current_tree_depth: int = 1', '', '        # loop until the stack is empty or n_connected_cells is reached', '        while stack and (len(visited_cells) < n_accessible_cells):', '            # get the current coord from the stack', '            current_coord: Coord = stack.pop()', '', '            # filter neighbors by being within grid bounds and being unvisited', '            unvisited_neighbors_deltas: list[tuple[Coord, Coord]] = [', '                (neighbor, delta)', '                for neighbor, delta in zip(', '                    current_coord + NEIGHBORS_MASK, NEIGHBORS_MASK', '                )', '                if (', '                    (tuple(neighbor) not in visited_cells)', '                    and (0 <= neighbor[0] < grid_shape[0])', '                    and (0 <= neighbor[1] < grid_shape[1])', '                )', '            ]', '', \"            # don't continue if max_tree_depth/2 is already reached (divide by 2 because we can branch to multiple directions)\", '            if unvisited_neighbors_deltas and (', '                current_tree_depth <= max_tree_depth / 2', '            ):', \"                # if we want a maze without forks, simply don't add the current coord back to the stack\", '                if do_forks:', '                    stack.append(current_coord)', '', '                # choose one of the unvisited neighbors', '                chosen_neighbor, delta = random.choice(unvisited_neighbors_deltas)', '', '                # add connection', '                dim: int = np.argmax(np.abs(delta))', '                # if positive, down/right from current coord', '                # if negative, up/left from current coord (down/right from neighbor)', '                clist_node: Coord = (', '                    current_coord if (delta.sum() > 0) else chosen_neighbor', '                )', '                connection_list[dim, clist_node[0], clist_node[1]] = True', '', '                # add to visited cells and stack', '                visited_cells.add(tuple(chosen_neighbor))', '                stack.append(chosen_neighbor)', '', '                # Update current tree depth', '                current_tree_depth += 1', '            else:', '                current_tree_depth -= 1', '', '        return LatticeMaze(', '            connection_list=connection_list,', '            generation_meta=dict(', '                func_name=\"gen_dfs\",', '                grid_shape=grid_shape,', '                start_coord=start_coord,', '                n_accessible_cells=int(n_accessible_cells),', '                max_tree_depth=int(max_tree_depth),', '                fully_connected=bool(len(visited_cells) == n_accessible_cells),', '                visited_cells={tuple(int(x) for x in coord) for coord in visited_cells},', '            ),', '        )']}, 'maze_ctor_kwargs': {'do_forks': False}, 'padding_token_index': 10, 'token_arr': ['<ADJLIST_START>', '<ADJLIST_END>', '<TARGET_START>', '<TARGET_END>', '<ORIGIN_START>', '<ORIGIN_END>', '<PATH_START>', '<PATH_END>', '<-->', ';', '<PADDING>', '(0,0)', '(0,1)', '(1,0)', '(1,1)', '(0,2)', '(2,0)', '(1,2)', '(2,1)', '(2,2)', '(0,3)', '(3,0)', '(3,1)', '(2,3)', '(3,2)', '(1,3)', '(3,3)', '(0,4)', '(2,4)', '(4,0)', '(1,4)', '(4,1)', '(4,2)', '(3,4)', '(4,3)', '(4,4)', '(0,5)', '(5,0)', '(5,1)', '(2,5)', '(5,2)', '(5,3)', '(4,5)', '(5,4)', '(1,5)', '(3,5)', '(5,5)', '(0,6)', '(2,6)', '(4,6)', '(6,0)', '(1,6)', '(6,1)', '(6,2)', '(3,6)', '(6,3)', '(6,4)', '(5,6)', '(6,5)', '(6,6)', '(0,7)', '(7,0)', '(7,1)', '(2,7)', '(7,2)', '(7,3)', '(4,7)', '(7,4)', '(7,5)', '(6,7)', '(7,6)', '(1,7)', '(3,7)', '(5,7)', '(7,7)'], 'tokenizer_map': {'<ADJLIST_START>': 0, '<ADJLIST_END>': 1, '<TARGET_START>': 2, '<TARGET_END>': 3, '<ORIGIN_START>': 4, '<ORIGIN_END>': 5, '<PATH_START>': 6, '<PATH_END>': 7, '<-->': 8, ';': 9, '<PADDING>': 10, '(0,0)': 11, '(0,1)': 12, '(1,0)': 13, '(1,1)': 14, '(0,2)': 15, '(2,0)': 16, '(1,2)': 17, '(2,1)': 18, '(2,2)': 19, '(0,3)': 20, '(3,0)': 21, '(3,1)': 22, '(2,3)': 23, '(3,2)': 24, '(1,3)': 25, '(3,3)': 26, '(0,4)': 27, '(2,4)': 28, '(4,0)': 29, '(1,4)': 30, '(4,1)': 31, '(4,2)': 32, '(3,4)': 33, '(4,3)': 34, '(4,4)': 35, '(0,5)': 36, '(5,0)': 37, '(5,1)': 38, '(2,5)': 39, '(5,2)': 40, '(5,3)': 41, '(4,5)': 42, '(5,4)': 43, '(1,5)': 44, '(3,5)': 45, '(5,5)': 46, '(0,6)': 47, '(2,6)': 48, '(4,6)': 49, '(6,0)': 50, '(1,6)': 51, '(6,1)': 52, '(6,2)': 53, '(3,6)': 54, '(6,3)': 55, '(6,4)': 56, '(5,6)': 57, '(6,5)': 58, '(6,6)': 59, '(0,7)': 60, '(7,0)': 61, '(7,1)': 62, '(2,7)': 63, '(7,2)': 64, '(7,3)': 65, '(4,7)': 66, '(7,4)': 67, '(7,5)': 68, '(6,7)': 69, '(7,6)': 70, '(1,7)': 71, '(3,7)': 72, '(5,7)': 73, '(7,7)': 74}, 'grid_shape': (8, 8), 'token_node_map': {'(0,0)': (0, 0), '(0,1)': (0, 1), '(1,0)': (1, 0), '(1,1)': (1, 1), '(0,2)': (0, 2), '(2,0)': (2, 0), '(1,2)': (1, 2), '(2,1)': (2, 1), '(2,2)': (2, 2), '(0,3)': (0, 3), '(3,0)': (3, 0), '(3,1)': (3, 1), '(2,3)': (2, 3), '(3,2)': (3, 2), '(1,3)': (1, 3), '(3,3)': (3, 3), '(0,4)': (0, 4), '(2,4)': (2, 4), '(4,0)': (4, 0), '(1,4)': (1, 4), '(4,1)': (4, 1), '(4,2)': (4, 2), '(3,4)': (3, 4), '(4,3)': (4, 3), '(4,4)': (4, 4), '(0,5)': (0, 5), '(5,0)': (5, 0), '(5,1)': (5, 1), '(2,5)': (2, 5), '(5,2)': (5, 2), '(5,3)': (5, 3), '(4,5)': (4, 5), '(5,4)': (5, 4), '(1,5)': (1, 5), '(3,5)': (3, 5), '(5,5)': (5, 5), '(0,6)': (0, 6), '(2,6)': (2, 6), '(4,6)': (4, 6), '(6,0)': (6, 0), '(1,6)': (1, 6), '(6,1)': (6, 1), '(6,2)': (6, 2), '(3,6)': (3, 6), '(6,3)': (6, 3), '(6,4)': (6, 4), '(5,6)': (5, 6), '(6,5)': (6, 5), '(6,6)': (6, 6), '(0,7)': (0, 7), '(7,0)': (7, 0), '(7,1)': (7, 1), '(2,7)': (2, 7), '(7,2)': (7, 2), '(7,3)': (7, 3), '(4,7)': (4, 7), '(7,4)': (7, 4), '(7,5)': (7, 5), '(6,7)': (6, 7), '(7,6)': (7, 6), '(1,7)': (1, 7), '(3,7)': (3, 7), '(5,7)': (5, 7), '(7,7)': (7, 7)}, 'n_tokens': 75}, 'model_cfg': {'__format__': 'BaseGPTConfig(SerializableDataclass)', 'name': 'custom-model', 'act_fn': 'gelu', 'd_model': 128, 'd_head': 32, 'n_layers': 6, 'weight_processing': {'are_layernorms_folded': False, 'are_weights_processed': False}, 'n_heads': 4}, 'train_cfg': {'__format__': 'TrainConfig(SerializableDataclass)', 'name': 'custom-train', 'evals_max_new_tokens': 8, 'validation_dataset_cfg': 10, 'optimizer': 'AdamW', 'optimizer_kwargs': {'lr': 1e-05}, 'batch_size': 32, 'dataloader_cfg': {'shuffle': True, 'num_workers': 4, 'drop_last': False}, 'intervals': None, 'intervals_count': {'print_loss': 1000, 'checkpoint': 20, 'eval_fast': 100, 'eval_slow': 50}}, 'name': 'hallway-medium', 'pretrainedtokenizer_kwargs': None}\n",
      "2023-06-15 03:09:21 INFO Initialized logger\n",
      "2023-06-15 03:09:21 INFO Summary logged, getting dataset\n",
      "loading dataset from ../data/custom-hallway-g8-n100K-a_dfs-h98637.zanj\n",
      "Got dataset custom-hallway with 100000 items. output.cfg.to_fname() = 'custom-hallway-g8-n100K-a_dfs-h98637'\n",
      "2023-06-15 03:09:49 INFO finished getting training dataset with 100000 samples\n",
      "2023-06-15 03:09:49 INFO got validation dataset by splitting training dataset into 100000 train and 100000 validation samples\n",
      "2023-06-15 03:09:49 INFO Loaded 100000 sequences\n",
      "2023-06-15 03:09:49 INFO Creating dataloader\n",
      "2023-06-15 03:09:49 INFO finished dataloader, passing to train()\n",
      "2023-06-15 03:09:49 INFO Initializing model\n",
      "Moving model to device:  cuda\n",
      "2023-06-15 03:09:49 INFO Initializing optimizer\n",
      "2023-06-15 03:10:24 INFO will train for 3125 batches, evals_enabled=True, with intervals: {'print_loss': 3, 'checkpoint': 156, 'eval_fast': 31, 'eval_slow': 62}\n",
      "2023-06-15 03:10:24 INFO Starting training\n",
      "2023-06-15 03:10:52 INFO Running evals: eval_fast\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m result: TrainingResult \u001b[39m=\u001b[39m train_model(\n\u001b[0;32m      2\u001b[0m \tbase_path\u001b[39m=\u001b[39;49mPATH_DATA,\n\u001b[0;32m      3\u001b[0m     cfg\u001b[39m=\u001b[39;49mCFG,\n\u001b[0;32m      4\u001b[0m \twandb_project\u001b[39m=\u001b[39;49mWandbProject\u001b[39m.\u001b[39;49mDEMO_NOTEBOOKS, \u001b[39m# change this to WandbProject.DEMO_NOTEBOOKS! INTEGRATION_TESTS is for CI testing\u001b[39;49;00m\n\u001b[0;32m      5\u001b[0m \tdo_generate_dataset\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m      6\u001b[0m \tdataset_verbose\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m      7\u001b[0m )\n",
      "File \u001b[1;32mF:\\KNC\\maze-transformer\\maze_transformer\\training\\train_model.py:146\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(base_path, wandb_project, cfg, cfg_file, cfg_names, do_generate_dataset, dataset_verbose, device, help, **kwargs)\u001b[0m\n\u001b[0;32m    143\u001b[0m dataloader: DataLoader \u001b[39m=\u001b[39m get_dataloader(dataset, cfg, logger)\n\u001b[0;32m    145\u001b[0m logger\u001b[39m.\u001b[39mprogress(\u001b[39m\"\u001b[39m\u001b[39mfinished dataloader, passing to train()\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 146\u001b[0m trained_model: ZanjHookedTransformer \u001b[39m=\u001b[39m train(\n\u001b[0;32m    147\u001b[0m     cfg\u001b[39m=\u001b[39;49mcfg,\n\u001b[0;32m    148\u001b[0m     dataloader\u001b[39m=\u001b[39;49mdataloader,\n\u001b[0;32m    149\u001b[0m     logger\u001b[39m=\u001b[39;49mlogger,\n\u001b[0;32m    150\u001b[0m     output_dir\u001b[39m=\u001b[39;49moutput_path,\n\u001b[0;32m    151\u001b[0m     device\u001b[39m=\u001b[39;49mdevice,\n\u001b[0;32m    152\u001b[0m     val_dataset\u001b[39m=\u001b[39;49mval_dataset,\n\u001b[0;32m    153\u001b[0m )\n\u001b[0;32m    155\u001b[0m \u001b[39mreturn\u001b[39;00m TrainingResult(\n\u001b[0;32m    156\u001b[0m     output_path\u001b[39m=\u001b[39moutput_path,\n\u001b[0;32m    157\u001b[0m     model\u001b[39m=\u001b[39mtrained_model,\n\u001b[0;32m    158\u001b[0m )\n",
      "File \u001b[1;32mF:\\KNC\\maze-transformer\\maze_transformer\\training\\training.py:143\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(cfg, dataloader, logger, output_dir, device, val_dataset, zanj, model)\u001b[0m\n\u001b[0;32m    141\u001b[0m         \u001b[39mif\u001b[39;00m iteration \u001b[39m%\u001b[39m intervals[interval_key] \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    142\u001b[0m             logger\u001b[39m.\u001b[39mprogress(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mRunning evals: \u001b[39m\u001b[39m{\u001b[39;00minterval_key\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 143\u001b[0m             scores: \u001b[39mdict\u001b[39m[\u001b[39mstr\u001b[39m, StatCounter] \u001b[39m=\u001b[39m evaluate_model(\n\u001b[0;32m    144\u001b[0m                 model\u001b[39m=\u001b[39;49mmodel,\n\u001b[0;32m    145\u001b[0m                 dataset\u001b[39m=\u001b[39;49mval_dataset,\n\u001b[0;32m    146\u001b[0m                 dataset_tokens\u001b[39m=\u001b[39;49mval_dataset_tokens,\n\u001b[0;32m    147\u001b[0m                 eval_functions\u001b[39m=\u001b[39;49mevals_dict,\n\u001b[0;32m    148\u001b[0m                 batch_size\u001b[39m=\u001b[39;49mcfg\u001b[39m.\u001b[39;49mtrain_cfg\u001b[39m.\u001b[39;49mbatch_size,\n\u001b[0;32m    149\u001b[0m                 max_new_tokens\u001b[39m=\u001b[39;49mcfg\u001b[39m.\u001b[39;49mtrain_cfg\u001b[39m.\u001b[39;49mevals_max_new_tokens,\n\u001b[0;32m    150\u001b[0m             )\n\u001b[0;32m    151\u001b[0m             metrics\u001b[39m.\u001b[39mupdate(scores)\n\u001b[0;32m    152\u001b[0m logger\u001b[39m.\u001b[39mlog_metric_hist(metrics)\n",
      "File \u001b[1;32mF:\\KNC\\maze-transformer\\maze_transformer\\evaluation\\eval_model.py:220\u001b[0m, in \u001b[0;36mevaluate_model\u001b[1;34m(model, dataset, dataset_tokens, eval_functions, max_new_tokens, batch_size, verbose)\u001b[0m\n\u001b[0;32m    218\u001b[0m \u001b[39mfor\u001b[39;00m batch \u001b[39min\u001b[39;00m chunks(\u001b[39mzip\u001b[39m(dataset, dataset_tokens), batch_size):\n\u001b[0;32m    219\u001b[0m     maze_batch, tokens_batch \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mbatch)\n\u001b[1;32m--> 220\u001b[0m     predictions: \u001b[39mlist\u001b[39m[\u001b[39mstr\u001b[39m \u001b[39m|\u001b[39m \u001b[39mlist\u001b[39m[\u001b[39mtuple\u001b[39m[\u001b[39mint\u001b[39m, \u001b[39mint\u001b[39m]]] \u001b[39m=\u001b[39m predict_maze_paths(\n\u001b[0;32m    221\u001b[0m         tokens_batch\u001b[39m=\u001b[39;49mtokens_batch,\n\u001b[0;32m    222\u001b[0m         data_cfg\u001b[39m=\u001b[39;49mdataset\u001b[39m.\u001b[39;49mcfg,\n\u001b[0;32m    223\u001b[0m         model\u001b[39m=\u001b[39;49mmodel,\n\u001b[0;32m    224\u001b[0m         max_new_tokens\u001b[39m=\u001b[39;49mmax_new_tokens,\n\u001b[0;32m    225\u001b[0m         verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[0;32m    226\u001b[0m     )\n\u001b[0;32m    228\u001b[0m     \u001b[39mfor\u001b[39;00m name, func \u001b[39min\u001b[39;00m eval_functions\u001b[39m.\u001b[39mitems():\n\u001b[0;32m    229\u001b[0m         score_counters[name]\u001b[39m.\u001b[39mupdate(\n\u001b[0;32m    230\u001b[0m             func(\n\u001b[0;32m    231\u001b[0m                 maze\u001b[39m=\u001b[39msolved_maze,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    236\u001b[0m             \u001b[39mfor\u001b[39;00m solved_maze, prediction \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(maze_batch, predictions)\n\u001b[0;32m    237\u001b[0m         )\n",
      "File \u001b[1;32mF:\\KNC\\maze-transformer\\maze_transformer\\evaluation\\eval_model.py:137\u001b[0m, in \u001b[0;36mpredict_maze_paths\u001b[1;34m(tokens_batch, data_cfg, model, max_new_tokens, verbose, when_noncoord, temperature)\u001b[0m\n\u001b[0;32m    135\u001b[0m context: \u001b[39mstr\u001b[39m \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(get_context_tokens(tokens))\n\u001b[0;32m    136\u001b[0m \u001b[39m# predict tokens\u001b[39;00m\n\u001b[1;32m--> 137\u001b[0m prediction: \u001b[39mstr\u001b[39m \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mgenerate(\n\u001b[0;32m    138\u001b[0m     context,\n\u001b[0;32m    139\u001b[0m     eos_token_id\u001b[39m=\u001b[39;49mdata_cfg\u001b[39m.\u001b[39;49mtokenizer_map[SPECIAL_TOKENS[\u001b[39m\"\u001b[39;49m\u001b[39mpath_end\u001b[39;49m\u001b[39m\"\u001b[39;49m]],\n\u001b[0;32m    140\u001b[0m     stop_at_eos\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m    141\u001b[0m     max_new_tokens\u001b[39m=\u001b[39;49mmax_new_tokens,\n\u001b[0;32m    142\u001b[0m     verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[0;32m    143\u001b[0m     temperature\u001b[39m=\u001b[39;49mtemperature,\n\u001b[0;32m    144\u001b[0m     \u001b[39m# use_past_kv_cache=False,\u001b[39;49;00m\n\u001b[0;32m    145\u001b[0m )\n\u001b[0;32m    146\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(\n\u001b[0;32m    147\u001b[0m     prediction, \u001b[39mstr\u001b[39m\n\u001b[0;32m    148\u001b[0m ), \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mprediction must be a string, got \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(prediction)\u001b[39m=}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mprediction\u001b[39m \u001b[39m\u001b[39m= }\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    149\u001b[0m \u001b[39m# convert to strings\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\mivan\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\maze-transformer-2cGx2R0F-py3.10\\lib\\site-packages\\torch\\autograd\\grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[0;32m     25\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m     26\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclone():\n\u001b[1;32m---> 27\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\mivan\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\maze-transformer-2cGx2R0F-py3.10\\lib\\site-packages\\transformer_lens\\HookedTransformer.py:1331\u001b[0m, in \u001b[0;36mHookedTransformer.generate\u001b[1;34m(self, input, max_new_tokens, stop_at_eos, eos_token_id, do_sample, top_k, top_p, temperature, freq_penalty, num_return_sequences, use_past_kv_cache, prepend_bos, return_type, verbose)\u001b[0m\n\u001b[0;32m   1325\u001b[0m         logits \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mforward(\n\u001b[0;32m   1326\u001b[0m             tokens[:, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m:],\n\u001b[0;32m   1327\u001b[0m             return_type\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mlogits\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1328\u001b[0m             past_kv_cache\u001b[39m=\u001b[39mpast_kv_cache,\n\u001b[0;32m   1329\u001b[0m         )\n\u001b[0;32m   1330\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1331\u001b[0m         logits \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward(\n\u001b[0;32m   1332\u001b[0m             tokens, return_type\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mlogits\u001b[39;49m\u001b[39m\"\u001b[39;49m, past_kv_cache\u001b[39m=\u001b[39;49mpast_kv_cache\n\u001b[0;32m   1333\u001b[0m         )\n\u001b[0;32m   1335\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1336\u001b[0m     \u001b[39m# We input the entire sequence, as a [batch, pos] tensor, since we aren't using the cache\u001b[39;00m\n\u001b[0;32m   1337\u001b[0m     logits \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mforward(tokens, return_type\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mlogits\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\mivan\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\maze-transformer-2cGx2R0F-py3.10\\lib\\site-packages\\transformer_lens\\HookedTransformer.py:325\u001b[0m, in \u001b[0;36mHookedTransformer.forward\u001b[1;34m(self, input, return_type, loss_per_token, prepend_bos, stop_at_layer, past_kv_cache)\u001b[0m\n\u001b[0;32m    320\u001b[0m     \u001b[39mif\u001b[39;00m shortformer_pos_embed \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    321\u001b[0m         shortformer_pos_embed \u001b[39m=\u001b[39m shortformer_pos_embed\u001b[39m.\u001b[39mto(\n\u001b[0;32m    322\u001b[0m             devices\u001b[39m.\u001b[39mget_device_for_block_index(i, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcfg)\n\u001b[0;32m    323\u001b[0m         )\n\u001b[1;32m--> 325\u001b[0m     residual \u001b[39m=\u001b[39m block(\n\u001b[0;32m    326\u001b[0m         residual,\n\u001b[0;32m    327\u001b[0m         past_kv_cache_entry\u001b[39m=\u001b[39;49mpast_kv_cache[i]\n\u001b[0;32m    328\u001b[0m         \u001b[39mif\u001b[39;49;00m past_kv_cache \u001b[39mis\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m\n\u001b[0;32m    329\u001b[0m         \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,  \u001b[39m# Cache contains a list of HookedTransformerKeyValueCache objects, one for each block\u001b[39;49;00m\n\u001b[0;32m    330\u001b[0m         shortformer_pos_embed\u001b[39m=\u001b[39;49mshortformer_pos_embed,\n\u001b[0;32m    331\u001b[0m     )  \u001b[39m# [batch, pos, d_model]\u001b[39;00m\n\u001b[0;32m    333\u001b[0m \u001b[39mif\u001b[39;00m stop_at_layer \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    334\u001b[0m     \u001b[39m# When we stop at an early layer, we end here rather than doing further computation\u001b[39;00m\n\u001b[0;32m    335\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\mivan\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\maze-transformer-2cGx2R0F-py3.10\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\mivan\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\maze-transformer-2cGx2R0F-py3.10\\lib\\site-packages\\transformer_lens\\components.py:768\u001b[0m, in \u001b[0;36mTransformerBlock.forward\u001b[1;34m(self, resid_pre, shortformer_pos_embed, past_kv_cache_entry)\u001b[0m\n\u001b[0;32m    758\u001b[0m     \u001b[39mif\u001b[39;00m shortformer_pos_embed \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    759\u001b[0m         shortformer_pos_embed \u001b[39m=\u001b[39m add_head_dimension(shortformer_pos_embed)\n\u001b[0;32m    761\u001b[0m attn_out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhook_attn_out(\n\u001b[0;32m    762\u001b[0m     \u001b[39m# hook the residual stream states that are used to calculate the \u001b[39;00m\n\u001b[0;32m    763\u001b[0m     \u001b[39m# queries, keys and values, independently. \u001b[39;00m\n\u001b[0;32m    764\u001b[0m     \u001b[39m# Then take the layer norm of these inputs, and pass these to the attention module.\u001b[39;00m\n\u001b[0;32m    765\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mattn(\n\u001b[0;32m    766\u001b[0m         query_input \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mln1(query_input) \u001b[39m+\u001b[39m (\u001b[39m0.0\u001b[39m \u001b[39mif\u001b[39;00m shortformer_pos_embed \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m shortformer_pos_embed),\n\u001b[0;32m    767\u001b[0m         key_input \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mln1(key_input) \u001b[39m+\u001b[39m (\u001b[39m0.0\u001b[39m \u001b[39mif\u001b[39;00m shortformer_pos_embed \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m shortformer_pos_embed),\n\u001b[1;32m--> 768\u001b[0m         value_input \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mln1(value_input),\n\u001b[0;32m    769\u001b[0m         past_kv_cache_entry\u001b[39m=\u001b[39mpast_kv_cache_entry,\n\u001b[0;32m    770\u001b[0m     )\n\u001b[0;32m    771\u001b[0m )  \u001b[39m# [batch, pos, d_model]\u001b[39;00m\n\u001b[0;32m    772\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcfg\u001b[39m.\u001b[39mattn_only \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcfg\u001b[39m.\u001b[39mparallel_attn_mlp:\n\u001b[0;32m    773\u001b[0m     resid_mid \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhook_resid_mid(\n\u001b[0;32m    774\u001b[0m         resid_pre \u001b[39m+\u001b[39m attn_out\n\u001b[0;32m    775\u001b[0m     )  \u001b[39m# [batch, pos, d_model]\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\mivan\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\maze-transformer-2cGx2R0F-py3.10\\lib\\site-packages\\torch\\nn\\modules\\module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39m\u001b[39minput\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32mc:\\Users\\mivan\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\maze-transformer-2cGx2R0F-py3.10\\lib\\site-packages\\transformer_lens\\components.py:161\u001b[0m, in \u001b[0;36mLayerNorm.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    157\u001b[0m scale: Float[torch\u001b[39m.\u001b[39mTensor, \u001b[39m\"\u001b[39m\u001b[39mbatch pos 1\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhook_scale(\n\u001b[0;32m    158\u001b[0m     (x\u001b[39m.\u001b[39mpow(\u001b[39m2\u001b[39m)\u001b[39m.\u001b[39mmean(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, keepdim\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m) \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39meps)\u001b[39m.\u001b[39msqrt()\n\u001b[0;32m    159\u001b[0m )\n\u001b[0;32m    160\u001b[0m x \u001b[39m=\u001b[39m x \u001b[39m/\u001b[39m scale  \u001b[39m# [batch, pos, length]\u001b[39;00m\n\u001b[1;32m--> 161\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhook_normalized(x \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mw \u001b[39m+\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mb)\n",
      "File \u001b[1;32mc:\\Users\\mivan\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\maze-transformer-2cGx2R0F-py3.10\\lib\\site-packages\\torch\\nn\\modules\\module.py:1256\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1253\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39m_is_full_backward_hook\u001b[39m\u001b[39m'\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__dict__\u001b[39m:\n\u001b[0;32m   1254\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_is_full_backward_hook \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 1256\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getattr__\u001b[39m(\u001b[39mself\u001b[39m, name: \u001b[39mstr\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Union[Tensor, \u001b[39m'\u001b[39m\u001b[39mModule\u001b[39m\u001b[39m'\u001b[39m]:\n\u001b[0;32m   1257\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39m_parameters\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__dict__\u001b[39m:\n\u001b[0;32m   1258\u001b[0m         _parameters \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__dict__\u001b[39m[\u001b[39m'\u001b[39m\u001b[39m_parameters\u001b[39m\u001b[39m'\u001b[39m]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "result: TrainingResult = train_model(\n",
    "\tbase_path=PATH_DATA,\n",
    "    cfg=CFG,\n",
    "\twandb_project=WandbProject.DEMO_NOTEBOOKS, # change this to WandbProject.DEMO_NOTEBOOKS! INTEGRATION_TESTS is for CI testing\n",
    "\tdo_generate_dataset=False,\n",
    "\tdataset_verbose=True,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "maze-transformer",
   "language": "python",
   "name": "maze-transformer"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
