{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Logit Lens and Direct Logit Attribution"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "In this notebook we explore how the model is doing prediction of the first path token in the maze (ie. the token that immediately comes after the `PATH_START` token), to this end we use:\n",
    "\n",
    "* Logit Lens\n",
    "* Direct Logit Attribution\n",
    "* Activation Patching\n",
    "\n",
    "In summary, we find that the majority of computation associated with this task is in the form of MLP computation (in particular in MLP10 and MLP11) but that there does appear to be a few heads within early layers (Layer 0, 1 and 2) that are also playing some role. Further evals outside of this notebook however are suggestive of this instance of maze-transformer doing some form of memorization (atleast overfitting to its training data and not generalising OOD), for this reason, this study has not yet been taken further.\n",
    "\n",
    "This notebook takes significant inspiration from two great resources:\n",
    "\n",
    "* Nanda's [Exploratory Analysis Demo](https://github.com/neelnanda-io/TransformerLens/blob/main/demos/Exploratory_Analysis_Demo.ipynb) Notebook\n",
    "* Janiak & Heimersheim's [Python docstrings](https://colab.research.google.com/drive/17CoA1yARaWHvV14zQGcI3ISz1bIRZKS5) Notebook"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Generic\n",
    "import os\n",
    "from pathlib import Path\n",
    "from copy import deepcopy\n",
    "import typing\n",
    "\n",
    "# Numerical Computing\n",
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "# import torch.nn.functional as F\n",
    "from fancy_einsum import einsum\n",
    "import einops\n",
    "from jaxtyping import Float, Int, Bool\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from muutils.misc import shorten_numerical_to_str\n",
    "from muutils.nbutils.configure_notebook import configure_notebook\n",
    "# TransformerLens imports\n",
    "from transformer_lens import ActivationCache\n",
    "\n",
    "# Our Code\n",
    "# dataset stuff\n",
    "from maze_dataset import MazeDataset, MazeDatasetConfig, SolvedMaze, LatticeMaze, SPECIAL_TOKENS\n",
    "from maze_dataset.tokenization import MazeTokenizer, TokenizationMode\n",
    "from maze_dataset.plotting.print_tokens import color_maze_tokens_AOTP\n",
    "\n",
    "# model stuff\n",
    "from maze_transformer.training.config import ConfigHolder, ZanjHookedTransformer, BaseGPTConfig\n",
    "\n",
    "# mechinterp stuff\n",
    "from maze_transformer.mechinterp.plot_logits import plot_logits\n",
    "from maze_transformer.mechinterp.logit_attrib_task import DLAProtocol, DLAProtocolFixed, token_after_fixed_start_token, LOGIT_ATTRIB_TASKS\n",
    "from maze_transformer.mechinterp.logit_diff import logits_diff_multi\n",
    "from maze_transformer.mechinterp.logit_lens import plot_logit_lens\n",
    "from maze_transformer.mechinterp.direct_logit_attribution import plot_direct_logit_attribution\n",
    "from maze_transformer.mechinterp.plot_attention import plot_attention_final_token\n",
    "from maze_transformer.mechinterp.plot_weights import plot_important_neurons\n",
    "from maze_transformer.utils.dict_shapes import string_dict_shapes\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Setup (we won't be training any models)\n",
    "DEVICE: torch.device = configure_notebook(seed=42, dark_mode=False)\n",
    "print(f\"{DEVICE = }\")\n",
    "torch.set_grad_enabled(False)\n",
    "\n",
    "# print the available logit attribution tasks\n",
    "print(f\"{list(LOGIT_ATTRIB_TASKS.keys()) = }\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## primary configuration\n",
    "\n",
    "this is where we pick the model to load, task to perform, dataset to use, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to load the model from\n",
    "MODEL_PATH: str = \"../examples/hallway-medium_2023-06-16-03-40-47.iter_26554.zanj\"\n",
    "# source for dataset config. Either add your own here, or it will copy the one from the model if set to None\n",
    "DATASET_CFG_SOURCE: MazeDatasetConfig|None = None\n",
    "# number of examples to run experiments on\n",
    "N_EXAMPLES: int = 10\n",
    "# task to perform\n",
    "LOGIT_ATTRIBUTION_TASK_NAME: str = \"path_end\"\n",
    "# if you have a custom task, set it here -- otherwise we will attempt to load one of the known tasks\n",
    "LOGIT_ATTRIBUTION_TASK: DLAProtocolFixed|None = None\n",
    "if LOGIT_ATTRIBUTION_TASK is None:\n",
    "    LOGIT_ATTRIBUTION_TASK = LOGIT_ATTRIB_TASKS[LOGIT_ATTRIBUTION_TASK_NAME]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Loading the model in\n",
    "\n",
    "By default, we load the small \"hallway\" model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL: ZanjHookedTransformer = ZanjHookedTransformer.read(MODEL_PATH)\n",
    "num_params: int = MODEL.num_params()\n",
    "print(f\"loaded model with {shorten_numerical_to_str(num_params)} params ({num_params = }) from\\n{MODEL_PATH}\")\n",
    "TOKENIZER: MazeTokenizer = MODEL.zanj_model_config.maze_tokenizer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Dataset Creation\n",
    "\n",
    "Creating a collection of mazes to have the model predict on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# copy config if needed, adjust number of mazes\n",
    "if DATASET_CFG_SOURCE is None:\n",
    "\tDATASET_CFG_SOURCE = deepcopy(MODEL.zanj_model_config.dataset_cfg)\n",
    "DATASET_CFG_SOURCE.n_mazes = N_EXAMPLES\n",
    "\n",
    "# get the dataset and tokens\n",
    "DATASET: MazeDataset = MazeDataset.from_config(DATASET_CFG_SOURCE)\n",
    "DATASET_TOKENS: list[list[str]] = DATASET.as_tokens(TOKENIZER, join_tokens_individual_maze=False)\n",
    "\n",
    "# print some info\n",
    "print(f\"loaded {len(DATASET_TOKENS)} mazes\")\n",
    "print(f\"first maze:\\n{' '.join(DATASET_TOKENS[0])}\")\n",
    "print(f\"first maze, colored:\\n{color_maze_tokens_AOTP(DATASET_TOKENS[0], fmt='terminal')}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "process the data into prompts and targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process with the task\n",
    "DATASET_PROMPTS: list[list[str]]; DATASET_TARGETS: list[str]\n",
    "DATASET_PROMPTS, DATASET_TARGETS = LOGIT_ATTRIBUTION_TASK(DATASET_TOKENS)\n",
    "\n",
    "DATASET_PROMPTS_JOINED: list[str] = [\" \".join(prompt) for prompt in DATASET_PROMPTS]\n",
    "DATASET_TARGET_IDS: Float[torch.Tensor, \"n_mazes\"] = torch.tensor(TOKENIZER.encode(DATASET_TARGETS), dtype=torch.long)\n",
    "\n",
    "print(\"for first maze:\")\n",
    "print(f\"full:\\n{' '.join(DATASET_PROMPTS[0])}\")\n",
    "print(f\"prompt:\\n{'[...] ' + DATASET_PROMPTS_JOINED[0][-150:]}\")\n",
    "print(f\"target:\\n{DATASET_TARGETS[0]}\")\n",
    "print(f\"target id:\\n{DATASET_TARGET_IDS[0]}\")\n",
    "plt.imshow(DATASET[0].as_pixels())\n",
    "\n",
    "n_mazes: int = len(DATASET_TOKENS)\n",
    "d_vocab: int = TOKENIZER.vocab_size"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# run model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOGITS: Float[torch.Tensor, \"n_mazes seq_len d_vocab\"]\n",
    "CACHE: ActivationCache\n",
    "\n",
    "LOGITS, CACHE = MODEL.run_with_cache(DATASET_PROMPTS_JOINED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{n_mazes = }, {d_vocab = }\")\n",
    "print(f\"{LOGITS.shape = }\")\n",
    "cache_shapes: dict[str, tuple[int, ...]] = {k: v.shape for k, v in CACHE.items()}\n",
    "print(f\"{cache_shapes = }\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we expect the logits to have shape `(n_mazes, n_tokens, n_vocab)`\n",
    "\n",
    "\n",
    "## get and evaluate predictions\n",
    "\n",
    "these should have shape `(n_mazes, n_vocab)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LAST_TOK_LOGITS: Float[torch.Tensor, \"n_mazes d_vocab\"] = LOGITS[:, -1, :]\n",
    "print(f\"{LAST_TOK_LOGITS.shape = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_logits(\n",
    "    last_tok_logits=LAST_TOK_LOGITS,\n",
    "    target_idxs=DATASET_TARGET_IDS,\n",
    "    tokenizer=TOKENIZER,\n",
    "    n_bins=50,\n",
    "    density=False,\n",
    "    logy=True,\n",
    "    show=False,\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PREDICTED_TOKENS: list[str] = TOKENIZER.decode(LAST_TOK_LOGITS.argmax(dim=-1).tolist())\n",
    "print(f\"{len(PREDICTED_TOKENS) = }\")\n",
    "print(f\"{DATASET_TARGETS[0] = }\")\n",
    "print(f\"{PREDICTED_TOKENS[0] = }\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## overall accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_correct: Bool[torch.Tensor, \"n_mazes\"] = torch.tensor([\n",
    "\tpred == target \n",
    "\tfor pred, target in zip(PREDICTED_TOKENS, DATASET_TARGETS)\n",
    "])\n",
    "\n",
    "# print(f\"{prediction_correct.shape = }\")\n",
    "print(f\"{prediction_correct.float().mean().item() = }\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## logit diff\n",
    "\n",
    "A logit difference $d$ can be interpreted as the model being $e^{d}$ times more likely to choose the correct response. Here, the `test` column tells us what token we are comparing: `taget` (correct) token, `predicted` (argmax sample) token, and `sampled` (sampled from logits) token. Also included are `noise={p}` (predicted with gaussian noise added to logits) and `random_r{i}` (a fully random one-hot vector). We compare these to either `all` other logits, or a `random` other vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOGIT_DIFF_DF: pd.DataFrame = logits_diff_multi(\n",
    "\tmodel=MODEL,\n",
    "\tcache=CACHE,\n",
    "\tdataset_target_ids=DATASET_TARGET_IDS,\n",
    "\tlast_tok_logits=LAST_TOK_LOGITS,\n",
    "\t# noise_sigmas=np.logspace(0, 3, 100),\n",
    ")\n",
    "\n",
    "print(LOGIT_DIFF_DF)\n",
    "\n",
    "# scatter separately for \"all\" vs \"random\"\n",
    "fig, ax = plt.subplots()\n",
    "for compare_to in [\"all\", \"random\"]:\n",
    "\tdf = LOGIT_DIFF_DF[LOGIT_DIFF_DF[\"compare_to\"] == compare_to]\n",
    "\tax.scatter(\n",
    "\t\tdf['result_orig'], df['result_res'], \n",
    "\t\tlabel=f\"comparing to {compare_to}\",\n",
    "\t\tmarker='o',\n",
    "\t)\n",
    "ax.legend()\n",
    "plt.xlabel('result_orig')\n",
    "plt.ylabel('result_res')\n",
    "plt.title('Scatter Plot between result_orig and result_res')\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## logit lens\n",
    "\n",
    "Here, we test the logit difference of the correct token at various layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figax, results = plot_logit_lens(\n",
    "    model=MODEL,\n",
    "    cache=CACHE,\n",
    "    answer_tokens=DATASET_TARGET_IDS,\n",
    "    show=False,\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## direct logit attribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax, DLA_DATA = plot_direct_logit_attribution(\n",
    "\tmodel=MODEL,\n",
    "\tcache=CACHE,\n",
    "    answer_tokens=DATASET_TARGET_IDS,\n",
    "    show=False,\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_important_neurons(\n",
    "    MODEL,\n",
    "    layer=-1,\n",
    "    neuron_dla_data=DLA_DATA[\"neurons\"],\n",
    "    n_important_neurons=50,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's try to plot the values of the attention heads for the top and bottom n contributing heads\n",
    "# (layer, head, value)\n",
    "top_heads: int = 5\n",
    "important_heads: list[tuple[int, int, float]] = sorted(\n",
    "    [\n",
    "        (i, j, DLA_DATA[\"heads\"][i, j])\n",
    "        for i in range(DLA_DATA[\"heads\"].shape[0])\n",
    "        for j in range(DLA_DATA[\"heads\"].shape[1])\n",
    "\t],\n",
    "    key=lambda x: abs(x[2]),\n",
    "    reverse=True,\n",
    ")[:top_heads]\n",
    "print(f\"{important_heads = }\")\n",
    "\n",
    "# plot the attention heads\n",
    "print(f\"{CACHE.keys() = }\")\n",
    "important_heads_scores = {\n",
    "    f\"layer_{i}.head_{j}\": (\n",
    "        c,\n",
    "        CACHE[f'blocks.{i}.attn.hook_attn_scores'][:, j, :, :].numpy(),\n",
    "    )\n",
    "    for i, j, c in important_heads\n",
    "}\n",
    "\n",
    "print(\"=\"*80)\n",
    "\n",
    "attn_final_tok_output = plot_attention_final_token(\n",
    "    important_heads_scores=important_heads_scores,\n",
    "    prompts=DATASET_PROMPTS,\n",
    "    targets=DATASET_TARGETS,\n",
    "    mazes=DATASET,\n",
    "    tokenizer=TOKENIZER,\n",
    "    n_mazes=5,\n",
    "    last_n_tokens=20,\n",
    "    exponentiate_scores=False,\n",
    "    plot_colored_tokens=True,\n",
    "    plot_scores=True,\n",
    "    maze_colormap_center=0.0,\n",
    "    show_all=True,\n",
    ")\n",
    "\n",
    "\n",
    "# TODO: total attention on coords within path as opposed to not in path?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "maze-transformer",
   "language": "python",
   "name": "maze-transformer"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
