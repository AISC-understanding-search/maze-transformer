{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we want to:\n",
    "\n",
    "- investigate the spatial structure of the residual stream\n",
    "- see which tokens the different directions in the residual stream map to"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mivan\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\maze-transformer-2cGx2R0F-py3.10\\lib\\site-packages\\_distutils_hack\\__init__.py:33: UserWarning: Setuptools is replacing distutils.\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\n"
     ]
    }
   ],
   "source": [
    "# Generic\n",
    "import os\n",
    "from pathlib import Path\n",
    "from copy import deepcopy\n",
    "import typing\n",
    "\n",
    "# Numerical Computing\n",
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "# import torch.nn.functional as F\n",
    "from fancy_einsum import einsum\n",
    "import einops\n",
    "from jaxtyping import Float, Int, Bool\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets\n",
    "\n",
    "from muutils.misc import shorten_numerical_to_str\n",
    "from muutils.nbutils.configure_notebook import configure_notebook\n",
    "# TransformerLens imports\n",
    "from transformer_lens import HookedTransformer, ActivationCache\n",
    "\n",
    "# Our Code\n",
    "from maze_dataset import MazeDataset, MazeDatasetConfig, SolvedMaze, LatticeMaze, SPECIAL_TOKENS\n",
    "from maze_dataset.tokenization import MazeTokenizer, TokenizationMode\n",
    "from maze_dataset.plotting.print_tokens import color_maze_tokens_AOTP\n",
    "from maze_dataset.tokenization.token_utils import strings_to_coords, coords_to_strings\n",
    "from maze_dataset.constants import _SPECIAL_TOKENS_ABBREVIATIONS\n",
    "\n",
    "from maze_transformer.training.config import ConfigHolder, ZanjHookedTransformer, BaseGPTConfig\n",
    "from maze_transformer.utils.dict_shapes import string_dict_shapes\n",
    "from maze_transformer.mechinterp.plot_weights import plot_embeddings\n",
    "from maze_transformer.mechinterp.residual_stream_structure import TokenPlottingInfo, process_tokens_for_pca, EmbeddingsPCAResult, compute_pca, plot_pca_colored\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEVICE = device(type='cpu')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch.autograd.grad_mode.set_grad_enabled at 0x213f0df2440>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setup (we won't be training any models)\n",
    "DEVICE: torch.device = configure_notebook(seed=42, dark_mode=False)\n",
    "print(f\"{DEVICE = }\")\n",
    "torch.set_grad_enabled(False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded model with 1.3M params (num_params = 1274699) from\n",
      "../examples/hallway-medium_2023-06-16-03-40-47.iter_26554.zanj\n"
     ]
    }
   ],
   "source": [
    "# path to load the model from\n",
    "MODEL_PATH: str = \"../examples/hallway-medium_2023-06-16-03-40-47.iter_26554.zanj\"\n",
    "# load the model and tokenizer\n",
    "MODEL: ZanjHookedTransformer = ZanjHookedTransformer.read(MODEL_PATH)\n",
    "num_params: int = MODEL.num_params()\n",
    "print(f\"loaded model with {shorten_numerical_to_str(num_params)} params ({num_params = }) from\\n{MODEL_PATH}\")\n",
    "TOKENIZER: MazeTokenizer = MODEL.zanj_model_config.maze_tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOKENIZER.token_arr = ['<ADJLIST_START>', '<ADJLIST_END>', '<TARGET_START>', '<TARGET_END>', '<ORIGIN_START>', '<ORIGIN_END>', '<PATH_START>', '<PATH_END>', '<-->', ';', '<PADDING>', '(0,0)', '(0,1)', '(1,0)', '(1,1)', '(0,2)', '(2,0)', '(1,2)', '(2,1)', '(2,2)', '(0,3)', '(3,0)', '(3,1)', '(2,3)', '(3,2)', '(1,3)', '(3,3)', '(0,4)', '(2,4)', '(4,0)', '(1,4)', '(4,1)', '(4,2)', '(3,4)', '(4,3)', '(4,4)', '(0,5)', '(5,0)', '(5,1)', '(2,5)', '(5,2)', '(5,3)', '(4,5)', '(5,4)', '(1,5)', '(3,5)', '(5,5)', '(0,6)', '(2,6)', '(4,6)', '(6,0)', '(1,6)', '(6,1)', '(6,2)', '(3,6)', '(6,3)', '(6,4)', '(5,6)', '(6,5)', '(6,6)', '(0,7)', '(7,0)', '(7,1)', '(2,7)', '(7,2)', '(7,3)', '(4,7)', '(7,4)', '(7,5)', '(6,7)', '(7,6)', '(1,7)', '(3,7)', '(5,7)', '(7,7)']\n",
      "torch.Size([75, 128])\n"
     ]
    }
   ],
   "source": [
    "# get tokenizer and embedding info\n",
    "print(f\"{TOKENIZER.token_arr = }\")\n",
    "d_model: int = MODEL.config.d_model\n",
    "print(MODEL.W_E.shape)\n",
    "assert MODEL.W_E.shape == (TOKENIZER.vocab_size, d_model)\n",
    "VOCAB_TOKENS: Int[torch.Tensor, \"vocab_size\"] = torch.arange(TOKENIZER.vocab_size, device=DEVICE)\n",
    "assert VOCAB_TOKENS.tolist() == TOKENIZER.encode(TOKENIZER.token_arr)\n",
    "\n",
    "# information for how to plot the tokens\n",
    "VOCAB_PLOT_INFO: list[TokenPlottingInfo] = process_tokens_for_pca(TOKENIZER)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA of token embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the PCA\n",
    "PCA_RESULTS: dict[str, EmbeddingsPCAResult] = compute_pca(\n",
    "    model=MODEL,\n",
    "    token_plotting_info=VOCAB_PLOT_INFO,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba262f37e2fa4733bf1ee2a2bd59c61d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='PCA Results:', options=('all', 'coords_only', 'special_only'), valâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ipywidgets.interact(\n",
    "    plot_pca_colored, \n",
    "    pca_results_options=ipywidgets.fixed(PCA_RESULTS),\n",
    "    pca_results_key=ipywidgets.Dropdown(\n",
    "        options=list(PCA_RESULTS.keys()),\n",
    "        value='all',\n",
    "        description='PCA Results:',\n",
    "    ),\n",
    "    vocab_colors=ipywidgets.fixed(VOCAB_PLOT_INFO), \n",
    "    dim1=ipywidgets.IntText(\n",
    "        value=1,\n",
    "        description='Dim 1:',\n",
    "    ),\n",
    "    dim2=ipywidgets.IntText(\n",
    "        value=2,\n",
    "        description='Dim 1:',\n",
    "    ),\n",
    "    lattice_connections=ipywidgets.Dropdown(\n",
    "        options=[True, False],\n",
    "        value=True,\n",
    "        description='Show Lattice:',\n",
    "    ),\n",
    ");"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "maze-transformer",
   "language": "python",
   "name": "maze-transformer"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
