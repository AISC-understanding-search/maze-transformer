<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>todo-inline</title>
  <style>
    html {
      line-height: 1.5;
      font-family: Georgia, serif;
      font-size: 20px;
      color: #1a1a1a;
      background-color: #fdfdfd;
    }
    body {
      margin: 0 auto;
      max-width: 36em;
      padding-left: 50px;
      padding-right: 50px;
      padding-top: 50px;
      padding-bottom: 50px;
      hyphens: auto;
      word-wrap: break-word;
      text-rendering: optimizeLegibility;
      font-kerning: normal;
    }
    @media (max-width: 600px) {
      body {
        font-size: 0.9em;
        padding: 1em;
      }
    }
    @media print {
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
    p {
      margin: 1em 0;
    }
    a {
      color: #1a1a1a;
    }
    a:visited {
      color: #1a1a1a;
    }
    img {
      max-width: 100%;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
    h5, h6 {
      font-size: 1em;
      font-style: italic;
    }
    h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {
      font-family: Menlo, Monaco, 'Lucida Console', Consolas, monospace;
      font-size: 85%;
      margin: 0;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      background-color: #1a1a1a;
      border: none;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    header {
      margin-bottom: 4em;
      text-align: center;
    }
    #TOC li {
      list-style: none;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    span.underline{text-decoration: underline;}
    div.column{display: inline-block; vertical-align: top; width: 50%;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    .display.math{display: block; text-align: center; margin: 0.5rem auto;}
  </style>
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
  <style>
  body {
    max-width: 50em;
  }
  </style>
</head>
<body>
<header id="title-block-header">
<h1 class="title">todo-inline</h1>
</header>
<nav id="TOC" role="doc-toc">
<ul>
<li><a href="#todo-6-items"><strong>TODO</strong> – 6 items</a></li>
<li><a href="#config-3-items"><strong>CONFIG</strong> – 3 items</a></li>
</ul>
</nav>
<h1 id="todo-6-items"><strong>TODO</strong> – 6 items</h1>
<h2 id="create_dataset.py-1-item"><a href="../create_dataset.py"><code>../create_dataset.py</code></a> – 1 item</h2>
<ul class="task-list">
<li><p><input type="checkbox" disabled="" />
TODO: figure out unexpected keyword argument linter error here? (line 55)</p><details>
<p>```python {.numberLines startFrom=“55”} # TODO: figure out unexpected keyword argument linter error here? cfg: MazeDatasetConfig = MazeDatasetConfig( name = name, grid_n = grid_n, n_mazes = n_mazes, **cfg_kwargs, ) # create and solve mazes c_start = (0, 0) c_end = (cfg.grid_n - 1, cfg.grid_n - 1) mazes: list[SolvedMaze]</p>
<p>with multiprocessing.Pool() as pool: ```</p>
</details></li>
</ul>
<h2 id="maze_transformertrainingmazedataset.py-2-items"><a href="../maze_transformer/training/mazedataset.py"><code>../maze_transformer/training/mazedataset.py</code></a> – 2 items</h2>
<ul class="task-list">
<li><p><input type="checkbox" disabled="" />
TODO: handling of minimum sequence length (line 196)</p><details>
<p><code>python {.numberLines startFrom="196"}      # TODO: handling of minimum sequence length      # last element in mazes_array.idxs whose value is smaller than `idx`      sequence_idx: int = torch.searchsorted(self.mazes_array.idxs, idx) - 1      # slice the array from the start of the sequence to `idx`, including `idx`      end_arr_idx: int = min(          idx + 1, # up to end of sequence          self.mazes_array.idxs[sequence_idx] + self.cfg.seq_len_max, # up to sequence length cutoff      )      subseq: ATensor = self.mazes_array.arr[ self.mazes_array.idxs[sequence_idx] : end_arr_idx ]      # left-pad the sequence      return torch.nn.functional.pad(subseq, (self.cfg.seq_len_max + 1 - len(subseq), 0), value=self.cfg.padding_token_idx)  def __len__(self) -&gt; int:      return len(self.mazes_array.arr)</code></p>
</details></li>
<li><p><input type="checkbox" disabled="" />
TODO: minimum separation (line 226)</p><details>
<p><code>python {.numberLines startFrom="226"}  # TODO: minimum separation  # n_min_tgt_dist: int = int(max(maze.grid_shape) * p_min_tgt_dist)  """if np.abs(start_node - end_node).sum() &lt; n_min_tgt_dist:      # if too close, move end node towards the corner opposite the start node      opposite_corner: CoordTup = (          maze.grid_shape[0] * round(start_node[0] / maze.grid_shape[0]),          maze.grid_shape[1] * round(start_node[1] / maze.grid_shape[1]),      )      # end_node +=  """  mazes: list[SolvedMaze] = list()  endpoint_nodes: NDArray[(("maze_idx", cfg.n_mazes), ("start_end", 2), ("coord", 2)), np.int8] = np.random.randint(0, cfg.grid_shape, (cfg.n_mazes, 2, 2))</code></p>
</details></li>
</ul>
<h2 id="maze_transformertrainingtraining.py-3-items"><a href="../maze_transformer/training/training.py"><code>../maze_transformer/training/training.py</code></a> – 3 items</h2>
<ul class="task-list">
<li><p><input type="checkbox" disabled="" />
TODO: check (near?) equality between <code>data_cfg</code> and <code>dataset.config</code> (line 165)</p><details>
<p><code>python {.numberLines startFrom="165"}  # TODO: check (near?) equality between `data_cfg` and `dataset.config`   # ensure the override of the sequence length is applied  # TODO: this is hacky  dataset.cfg = data_cfg  logger.log_elapsed_last()  logger.mem_usage()  length_stats: StatCounter = StatCounter(dataset.get_all_lengths())  logger.log({"dataset_seq_len_stats": length_stats.summary()})  logger.log({"dataset_seq_len_stats": length_stats.serialize()}, lvl=50)  logger.log(f"loaded {len(dataset)} sequences", 20)  logger.log("creating dataloader", 10)  dataloader: DataLoader = DataLoader(      dataset,</code></p>
</details></li>
<li><p><input type="checkbox" disabled="" />
TODO: this is hacky (line 167)</p><details>
<p><code>python {.numberLines startFrom="167"}  # TODO: this is hacky  dataset.cfg = data_cfg  logger.log_elapsed_last()  logger.mem_usage()  length_stats: StatCounter = StatCounter(dataset.get_all_lengths())  logger.log({"dataset_seq_len_stats": length_stats.summary()})  logger.log({"dataset_seq_len_stats": length_stats.serialize()}, lvl=50)  logger.log(f"loaded {len(dataset)} sequences", 20)  logger.log("creating dataloader", 10)  dataloader: DataLoader = DataLoader(      dataset,       batch_size = train_cfg.batch_size,      **train_cfg.dataloader_cfg,</code></p>
</details></li>
<li><p><input type="checkbox" disabled="" />
TODO: this is a bit hacky (line 75)</p><details>
<p><code>python {.numberLines startFrom="75"}  # TODO: this is a bit hacky  if train_cfg.seq_len_max is not None:      data_cfg.seq_len_max = train_cfg.seq_len_max  # set up paths  basepath_train: Path = basepath / train_dir  os.makedirs(basepath_train, exist_ok = True)  os.makedirs(basepath_train / TRAIN_SAVE_FILES.checkpoints, exist_ok = True)  with open(basepath_train / TRAIN_SAVE_FILES.cfg, "w") as f:      json.dump(json_serialize(data_cfg), f, indent = "\t")  # set up logger  logger: Logger = Logger(      log_path=Path(basepath_train / TRAIN_SAVE_FILES.log).as_posix(),      console_print_threshold=30,</code></p>
</details></li>
</ul>
<h1 id="config-3-items"><strong>CONFIG</strong> – 3 items</h1>
<h2 id="maze_transformertrainingconfig.py-3-items"><a href="../maze_transformer/training/config.py"><code>../maze_transformer/training/config.py</code></a> – 3 items</h2>
<ul class="task-list">
<li><p><input type="checkbox" disabled="" />
CONFIGS_LIST: list[BaseGPTConfig] = [ (line 116)</p><details>
<p><code>python {.numberLines startFrom="116"}  _GPT_CONFIGS_LIST: list[BaseGPTConfig] = [      BaseGPTConfig(          gpt_cfg_name = "tiny-v1",          n_embed=32,          n_layer=4,          n_head=2,      ),      BaseGPTConfig(          gpt_cfg_name = "medium-v1",          n_embed=128,          n_layer=8,          n_head=4,      ),  ]</code></p>
</details></li>
<li><p><input type="checkbox" disabled="" />
CONFIGS: dict[str, BaseGPTConfig] = { (line 131)</p><details>
<p><code>python {.numberLines startFrom="131"}  GPT_CONFIGS: dict[str, BaseGPTConfig] = {      cfg.gpt_cfg_name: cfg       for cfg in _GPT_CONFIGS_LIST  }  _TRAINING_CONFIG_LIST: list[TrainConfig] = [      TrainConfig(          name = "tiny-v1",          base_gpt_cfg = GPT_CONFIGS["tiny-v1"],          optimizer = torch.optim.RMSprop,          optimizer_kwargs = dict(lr = 0.000001),          batch_size = 32,          dataloader_cfg = dict(              shuffle = True,</code></p>
</details></li>
<li><p><input type="checkbox" disabled="" />
CONFIGS: dict[str, TrainConfig] = { (line 157)</p><details>
<p><code>python {.numberLines startFrom="157"}  TRAINING_CONFIGS: dict[str, TrainConfig] = {      cfg.name: cfg       for cfg in _TRAINING_CONFIG_LIST  }</code></p>
</details></li>
</ul>
</body>
</html>
